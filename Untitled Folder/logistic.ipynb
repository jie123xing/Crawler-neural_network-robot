{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "num_epoches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练集 MNIST 手写数字训练集\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "\n",
    "    root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Logistic Regression 模型\n",
    "\n",
    "class Logstic_Regression(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, n_class):\n",
    "\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "\n",
    "        self.logstic = nn.Linear(in_dim, n_class)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.logstic(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Logstic_Regression(28 * 28, 10)  # 图片大小是28x28\n",
    "\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "\n",
    "if use_gpu:\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "# 定义loss和optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "epoch 1\n",
      "[1/100] Loss: 1.200962, Acc: 0.798854\n",
      "[1/100] Loss: 1.162999, Acc: 0.803594\n",
      "[1/100] Loss: 1.126618, Acc: 0.808854\n",
      "[1/100] Loss: 1.098802, Acc: 0.811667\n",
      "[1/100] Loss: 1.070919, Acc: 0.814500\n",
      "[1/100] Loss: 1.048679, Acc: 0.816111\n",
      "Finish 1 epoch, Loss: 1.043446, Acc: 0.816683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:91: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "I:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:93: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.880771, Acc: 0.841400\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 2\n",
      "[2/100] Loss: 0.889827, Acc: 0.833125\n",
      "[2/100] Loss: 0.877464, Acc: 0.833281\n",
      "[2/100] Loss: 0.867640, Acc: 0.832431\n",
      "[2/100] Loss: 0.850078, Acc: 0.836224\n",
      "[2/100] Loss: 0.841344, Acc: 0.836542\n",
      "[2/100] Loss: 0.829250, Acc: 0.837917\n",
      "Finish 2 epoch, Loss: 0.826896, Acc: 0.837667\n",
      "Test Loss: 0.735379, Acc: 0.854800\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 3\n",
      "[3/100] Loss: 0.764338, Acc: 0.844375\n",
      "[3/100] Loss: 0.748265, Acc: 0.845729\n",
      "[3/100] Loss: 0.739678, Acc: 0.845972\n",
      "[3/100] Loss: 0.733746, Acc: 0.846406\n",
      "[3/100] Loss: 0.727405, Acc: 0.847083\n",
      "[3/100] Loss: 0.719760, Acc: 0.848125\n",
      "Finish 3 epoch, Loss: 0.717587, Acc: 0.848750\n",
      "Test Loss: 0.652738, Acc: 0.862900\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 4\n",
      "[4/100] Loss: 0.669465, Acc: 0.853958\n",
      "[4/100] Loss: 0.665729, Acc: 0.856510\n",
      "[4/100] Loss: 0.661176, Acc: 0.856736\n",
      "[4/100] Loss: 0.657324, Acc: 0.855885\n",
      "[4/100] Loss: 0.654610, Acc: 0.855583\n",
      "[4/100] Loss: 0.650837, Acc: 0.856476\n",
      "Finish 4 epoch, Loss: 0.650593, Acc: 0.856167\n",
      "Test Loss: 0.598778, Acc: 0.869600\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 5\n",
      "[5/100] Loss: 0.627174, Acc: 0.856979\n",
      "[5/100] Loss: 0.623363, Acc: 0.859479\n",
      "[5/100] Loss: 0.614558, Acc: 0.861736\n",
      "[5/100] Loss: 0.613387, Acc: 0.860625\n",
      "[5/100] Loss: 0.611173, Acc: 0.860479\n",
      "[5/100] Loss: 0.606342, Acc: 0.860972\n",
      "Finish 5 epoch, Loss: 0.604734, Acc: 0.861317\n",
      "Test Loss: 0.560390, Acc: 0.874300\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 6\n",
      "[6/100] Loss: 0.582889, Acc: 0.862604\n",
      "[6/100] Loss: 0.584330, Acc: 0.861927\n",
      "[6/100] Loss: 0.580869, Acc: 0.864167\n",
      "[6/100] Loss: 0.578573, Acc: 0.863568\n",
      "[6/100] Loss: 0.575199, Acc: 0.864521\n",
      "[6/100] Loss: 0.570992, Acc: 0.866163\n",
      "Finish 6 epoch, Loss: 0.570991, Acc: 0.865800\n",
      "Test Loss: 0.531450, Acc: 0.877000\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 7\n",
      "[7/100] Loss: 0.562675, Acc: 0.864688\n",
      "[7/100] Loss: 0.563313, Acc: 0.864323\n",
      "[7/100] Loss: 0.557580, Acc: 0.865903\n",
      "[7/100] Loss: 0.549466, Acc: 0.869010\n",
      "[7/100] Loss: 0.548749, Acc: 0.868771\n",
      "[7/100] Loss: 0.545114, Acc: 0.869410\n",
      "Finish 7 epoch, Loss: 0.544918, Acc: 0.869333\n",
      "Test Loss: 0.508700, Acc: 0.880200\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 8\n",
      "[8/100] Loss: 0.518915, Acc: 0.874271\n",
      "[8/100] Loss: 0.526691, Acc: 0.871563\n",
      "[8/100] Loss: 0.529954, Acc: 0.871250\n",
      "[8/100] Loss: 0.529259, Acc: 0.870391\n",
      "[8/100] Loss: 0.527757, Acc: 0.870646\n",
      "[8/100] Loss: 0.524570, Acc: 0.871701\n",
      "Finish 8 epoch, Loss: 0.524079, Acc: 0.871800\n",
      "Test Loss: 0.490155, Acc: 0.882400\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 9\n",
      "[9/100] Loss: 0.505006, Acc: 0.875000\n",
      "[9/100] Loss: 0.510684, Acc: 0.872760\n",
      "[9/100] Loss: 0.511590, Acc: 0.872674\n",
      "[9/100] Loss: 0.507531, Acc: 0.874453\n",
      "[9/100] Loss: 0.509816, Acc: 0.873250\n",
      "[9/100] Loss: 0.508235, Acc: 0.873715\n",
      "Finish 9 epoch, Loss: 0.506943, Acc: 0.874183\n",
      "Test Loss: 0.474849, Acc: 0.884800\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 10\n",
      "[10/100] Loss: 0.511052, Acc: 0.873437\n",
      "[10/100] Loss: 0.508319, Acc: 0.873021\n",
      "[10/100] Loss: 0.501384, Acc: 0.875417\n",
      "[10/100] Loss: 0.500422, Acc: 0.875391\n",
      "[10/100] Loss: 0.495434, Acc: 0.875854\n",
      "[10/100] Loss: 0.492669, Acc: 0.876458\n",
      "Finish 10 epoch, Loss: 0.492534, Acc: 0.876533\n",
      "Test Loss: 0.461960, Acc: 0.886300\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 11\n",
      "[11/100] Loss: 0.474565, Acc: 0.883542\n",
      "[11/100] Loss: 0.485744, Acc: 0.879219\n",
      "[11/100] Loss: 0.483120, Acc: 0.878472\n",
      "[11/100] Loss: 0.483722, Acc: 0.877604\n",
      "[11/100] Loss: 0.482785, Acc: 0.877958\n",
      "[11/100] Loss: 0.480549, Acc: 0.878385\n",
      "Finish 11 epoch, Loss: 0.480198, Acc: 0.878633\n",
      "Test Loss: 0.450717, Acc: 0.888100\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 12\n",
      "[12/100] Loss: 0.467933, Acc: 0.881146\n",
      "[12/100] Loss: 0.468239, Acc: 0.881615\n",
      "[12/100] Loss: 0.470042, Acc: 0.880000\n",
      "[12/100] Loss: 0.469677, Acc: 0.880156\n",
      "[12/100] Loss: 0.469792, Acc: 0.880958\n",
      "[12/100] Loss: 0.469970, Acc: 0.880347\n",
      "Finish 12 epoch, Loss: 0.469522, Acc: 0.880583\n",
      "Test Loss: 0.441004, Acc: 0.890000\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 13\n",
      "[13/100] Loss: 0.461627, Acc: 0.881042\n",
      "[13/100] Loss: 0.462167, Acc: 0.882240\n",
      "[13/100] Loss: 0.459428, Acc: 0.882743\n",
      "[13/100] Loss: 0.459779, Acc: 0.882240\n",
      "[13/100] Loss: 0.461091, Acc: 0.882146\n",
      "[13/100] Loss: 0.460027, Acc: 0.882309\n",
      "Finish 13 epoch, Loss: 0.460144, Acc: 0.882117\n",
      "Test Loss: 0.432469, Acc: 0.891000\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 14\n",
      "[14/100] Loss: 0.453519, Acc: 0.883021\n",
      "[14/100] Loss: 0.450315, Acc: 0.884583\n",
      "[14/100] Loss: 0.452639, Acc: 0.883715\n",
      "[14/100] Loss: 0.454637, Acc: 0.883255\n",
      "[14/100] Loss: 0.454131, Acc: 0.883229\n",
      "[14/100] Loss: 0.452923, Acc: 0.883559\n",
      "Finish 14 epoch, Loss: 0.451820, Acc: 0.883817\n",
      "Test Loss: 0.424959, Acc: 0.892100\n",
      "Time:16.9 s\n",
      "\n",
      "**********\n",
      "epoch 15\n",
      "[15/100] Loss: 0.452880, Acc: 0.883021\n",
      "[15/100] Loss: 0.447837, Acc: 0.883698\n",
      "[15/100] Loss: 0.445840, Acc: 0.885312\n",
      "[15/100] Loss: 0.445782, Acc: 0.884792\n",
      "[15/100] Loss: 0.446030, Acc: 0.884792\n",
      "[15/100] Loss: 0.444552, Acc: 0.885052\n",
      "Finish 15 epoch, Loss: 0.444371, Acc: 0.884900\n",
      "Test Loss: 0.418129, Acc: 0.892900\n",
      "Time:17.2 s\n",
      "\n",
      "**********\n",
      "epoch 16\n",
      "[16/100] Loss: 0.426079, Acc: 0.892083\n",
      "[16/100] Loss: 0.433590, Acc: 0.889948\n",
      "[16/100] Loss: 0.437789, Acc: 0.887743\n",
      "[16/100] Loss: 0.437007, Acc: 0.888047\n",
      "[16/100] Loss: 0.438282, Acc: 0.886354\n",
      "[16/100] Loss: 0.438269, Acc: 0.885938\n",
      "Finish 16 epoch, Loss: 0.437662, Acc: 0.886033\n",
      "Test Loss: 0.411978, Acc: 0.893800\n",
      "Time:18.6 s\n",
      "\n",
      "**********\n",
      "epoch 17\n",
      "[17/100] Loss: 0.435338, Acc: 0.884167\n",
      "[17/100] Loss: 0.435489, Acc: 0.885469\n",
      "[17/100] Loss: 0.434296, Acc: 0.885833\n",
      "[17/100] Loss: 0.432265, Acc: 0.886589\n",
      "[17/100] Loss: 0.431986, Acc: 0.887167\n",
      "[17/100] Loss: 0.430938, Acc: 0.887205\n",
      "Finish 17 epoch, Loss: 0.431573, Acc: 0.887033\n",
      "Test Loss: 0.406356, Acc: 0.894600\n",
      "Time:17.8 s\n",
      "\n",
      "**********\n",
      "epoch 18\n",
      "[18/100] Loss: 0.431666, Acc: 0.886354\n",
      "[18/100] Loss: 0.428907, Acc: 0.887240\n",
      "[18/100] Loss: 0.428300, Acc: 0.887014\n",
      "[18/100] Loss: 0.426423, Acc: 0.888021\n",
      "[18/100] Loss: 0.425970, Acc: 0.888062\n",
      "[18/100] Loss: 0.426083, Acc: 0.888281\n",
      "Finish 18 epoch, Loss: 0.426013, Acc: 0.888317\n",
      "Test Loss: 0.401321, Acc: 0.895500\n",
      "Time:17.9 s\n",
      "\n",
      "**********\n",
      "epoch 19\n",
      "[19/100] Loss: 0.427196, Acc: 0.888542\n",
      "[19/100] Loss: 0.421437, Acc: 0.890365\n",
      "[19/100] Loss: 0.421601, Acc: 0.888993\n",
      "[19/100] Loss: 0.420756, Acc: 0.889740\n",
      "[19/100] Loss: 0.422743, Acc: 0.888729\n",
      "[19/100] Loss: 0.421241, Acc: 0.889028\n",
      "Finish 19 epoch, Loss: 0.420902, Acc: 0.888983\n",
      "Test Loss: 0.396704, Acc: 0.896500\n",
      "Time:17.3 s\n",
      "\n",
      "**********\n",
      "epoch 20\n",
      "[20/100] Loss: 0.417937, Acc: 0.888229\n",
      "[20/100] Loss: 0.419908, Acc: 0.887188\n",
      "[20/100] Loss: 0.421428, Acc: 0.887500\n",
      "[20/100] Loss: 0.417047, Acc: 0.888958\n",
      "[20/100] Loss: 0.416320, Acc: 0.889708\n",
      "[20/100] Loss: 0.415569, Acc: 0.889826\n",
      "Finish 20 epoch, Loss: 0.416192, Acc: 0.889783\n",
      "Test Loss: 0.392321, Acc: 0.896700\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 21\n",
      "[21/100] Loss: 0.421249, Acc: 0.885938\n",
      "[21/100] Loss: 0.415105, Acc: 0.889115\n",
      "[21/100] Loss: 0.410935, Acc: 0.890764\n",
      "[21/100] Loss: 0.410107, Acc: 0.890625\n",
      "[21/100] Loss: 0.411569, Acc: 0.890417\n",
      "[21/100] Loss: 0.412424, Acc: 0.890486\n",
      "Finish 21 epoch, Loss: 0.411852, Acc: 0.890583\n",
      "Test Loss: 0.388360, Acc: 0.897200\n",
      "Time:22.7 s\n",
      "\n",
      "**********\n",
      "epoch 22\n",
      "[22/100] Loss: 0.403408, Acc: 0.892604\n",
      "[22/100] Loss: 0.410890, Acc: 0.890521\n",
      "[22/100] Loss: 0.409623, Acc: 0.890764\n",
      "[22/100] Loss: 0.406486, Acc: 0.891927\n",
      "[22/100] Loss: 0.406787, Acc: 0.892167\n",
      "[22/100] Loss: 0.406976, Acc: 0.891858\n",
      "Finish 22 epoch, Loss: 0.407797, Acc: 0.891417\n",
      "Test Loss: 0.384648, Acc: 0.898200\n",
      "Time:18.6 s\n",
      "\n",
      "**********\n",
      "epoch 23\n",
      "[23/100] Loss: 0.410557, Acc: 0.889896\n",
      "[23/100] Loss: 0.410355, Acc: 0.889844\n",
      "[23/100] Loss: 0.406736, Acc: 0.890312\n",
      "[23/100] Loss: 0.406777, Acc: 0.890104\n",
      "[23/100] Loss: 0.404694, Acc: 0.891229\n",
      "[23/100] Loss: 0.404543, Acc: 0.892014\n",
      "Finish 23 epoch, Loss: 0.404023, Acc: 0.892233\n",
      "Test Loss: 0.381168, Acc: 0.899000\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 24\n",
      "[24/100] Loss: 0.404838, Acc: 0.891042\n",
      "[24/100] Loss: 0.400394, Acc: 0.892917\n",
      "[24/100] Loss: 0.404039, Acc: 0.892188\n",
      "[24/100] Loss: 0.401894, Acc: 0.892318\n",
      "[24/100] Loss: 0.403407, Acc: 0.891604\n",
      "[24/100] Loss: 0.401783, Acc: 0.892326\n",
      "Finish 24 epoch, Loss: 0.400495, Acc: 0.892800\n",
      "Test Loss: 0.377951, Acc: 0.900400\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 25\n",
      "[25/100] Loss: 0.392621, Acc: 0.895625\n",
      "[25/100] Loss: 0.393623, Acc: 0.893958\n",
      "[25/100] Loss: 0.389677, Acc: 0.894479\n",
      "[25/100] Loss: 0.393036, Acc: 0.894687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/100] Loss: 0.395697, Acc: 0.893792\n",
      "[25/100] Loss: 0.396207, Acc: 0.893646\n",
      "Finish 25 epoch, Loss: 0.397179, Acc: 0.893633\n",
      "Test Loss: 0.374961, Acc: 0.900000\n",
      "Time:18.7 s\n",
      "\n",
      "**********\n",
      "epoch 26\n",
      "[26/100] Loss: 0.394464, Acc: 0.892604\n",
      "[26/100] Loss: 0.388958, Acc: 0.896823\n",
      "[26/100] Loss: 0.396175, Acc: 0.894757\n",
      "[26/100] Loss: 0.393523, Acc: 0.894375\n",
      "[26/100] Loss: 0.392632, Acc: 0.895021\n",
      "[26/100] Loss: 0.392705, Acc: 0.894618\n",
      "Finish 26 epoch, Loss: 0.394062, Acc: 0.894333\n",
      "Test Loss: 0.372177, Acc: 0.901000\n",
      "Time:17.7 s\n",
      "\n",
      "**********\n",
      "epoch 27\n",
      "[27/100] Loss: 0.402270, Acc: 0.893229\n",
      "[27/100] Loss: 0.396686, Acc: 0.893385\n",
      "[27/100] Loss: 0.392314, Acc: 0.895174\n",
      "[27/100] Loss: 0.392686, Acc: 0.894089\n",
      "[27/100] Loss: 0.391384, Acc: 0.894500\n",
      "[27/100] Loss: 0.390557, Acc: 0.894722\n",
      "Finish 27 epoch, Loss: 0.391121, Acc: 0.894817\n",
      "Test Loss: 0.369522, Acc: 0.901100\n",
      "Time:16.5 s\n",
      "\n",
      "**********\n",
      "epoch 28\n",
      "[28/100] Loss: 0.398959, Acc: 0.892292\n",
      "[28/100] Loss: 0.397799, Acc: 0.891875\n",
      "[28/100] Loss: 0.395182, Acc: 0.892535\n",
      "[28/100] Loss: 0.393963, Acc: 0.893437\n",
      "[28/100] Loss: 0.389888, Acc: 0.894708\n",
      "[28/100] Loss: 0.389412, Acc: 0.895017\n",
      "Finish 28 epoch, Loss: 0.388330, Acc: 0.895267\n",
      "Test Loss: 0.367054, Acc: 0.901800\n",
      "Time:17.3 s\n",
      "\n",
      "**********\n",
      "epoch 29\n",
      "[29/100] Loss: 0.383309, Acc: 0.895000\n",
      "[29/100] Loss: 0.384008, Acc: 0.895208\n",
      "[29/100] Loss: 0.384271, Acc: 0.895069\n",
      "[29/100] Loss: 0.383693, Acc: 0.896276\n",
      "[29/100] Loss: 0.384677, Acc: 0.895979\n",
      "[29/100] Loss: 0.385104, Acc: 0.895972\n",
      "Finish 29 epoch, Loss: 0.385711, Acc: 0.895683\n",
      "Test Loss: 0.364457, Acc: 0.903000\n",
      "Time:17.8 s\n",
      "\n",
      "**********\n",
      "epoch 30\n",
      "[30/100] Loss: 0.388169, Acc: 0.894062\n",
      "[30/100] Loss: 0.394361, Acc: 0.891250\n",
      "[30/100] Loss: 0.385657, Acc: 0.895035\n",
      "[30/100] Loss: 0.385653, Acc: 0.895990\n",
      "[30/100] Loss: 0.383537, Acc: 0.896479\n",
      "[30/100] Loss: 0.384362, Acc: 0.896094\n",
      "Finish 30 epoch, Loss: 0.383207, Acc: 0.896383\n",
      "Test Loss: 0.362352, Acc: 0.903200\n",
      "Time:17.6 s\n",
      "\n",
      "**********\n",
      "epoch 31\n",
      "[31/100] Loss: 0.382021, Acc: 0.897708\n",
      "[31/100] Loss: 0.383206, Acc: 0.896146\n",
      "[31/100] Loss: 0.383991, Acc: 0.895660\n",
      "[31/100] Loss: 0.381992, Acc: 0.896667\n",
      "[31/100] Loss: 0.381907, Acc: 0.896437\n",
      "[31/100] Loss: 0.380040, Acc: 0.897240\n",
      "Finish 31 epoch, Loss: 0.380840, Acc: 0.896950\n",
      "Test Loss: 0.360172, Acc: 0.903500\n",
      "Time:17.3 s\n",
      "\n",
      "**********\n",
      "epoch 32\n",
      "[32/100] Loss: 0.378074, Acc: 0.896458\n",
      "[32/100] Loss: 0.378370, Acc: 0.899219\n",
      "[32/100] Loss: 0.375807, Acc: 0.899653\n",
      "[32/100] Loss: 0.373532, Acc: 0.899271\n",
      "[32/100] Loss: 0.374674, Acc: 0.898625\n",
      "[32/100] Loss: 0.377067, Acc: 0.897951\n",
      "Finish 32 epoch, Loss: 0.378561, Acc: 0.897433\n",
      "Test Loss: 0.358075, Acc: 0.903600\n",
      "Time:17.9 s\n",
      "\n",
      "**********\n",
      "epoch 33\n",
      "[33/100] Loss: 0.363471, Acc: 0.899896\n",
      "[33/100] Loss: 0.367093, Acc: 0.899427\n",
      "[33/100] Loss: 0.374174, Acc: 0.897569\n",
      "[33/100] Loss: 0.375191, Acc: 0.897682\n",
      "[33/100] Loss: 0.375728, Acc: 0.897875\n",
      "[33/100] Loss: 0.376673, Acc: 0.897431\n",
      "Finish 33 epoch, Loss: 0.376408, Acc: 0.897533\n",
      "Test Loss: 0.356109, Acc: 0.903900\n",
      "Time:17.3 s\n",
      "\n",
      "**********\n",
      "epoch 34\n",
      "[34/100] Loss: 0.377931, Acc: 0.897500\n",
      "[34/100] Loss: 0.379845, Acc: 0.894323\n",
      "[34/100] Loss: 0.374323, Acc: 0.897743\n",
      "[34/100] Loss: 0.372507, Acc: 0.898307\n",
      "[34/100] Loss: 0.373084, Acc: 0.898729\n",
      "[34/100] Loss: 0.374192, Acc: 0.898021\n",
      "Finish 34 epoch, Loss: 0.374356, Acc: 0.898100\n",
      "Test Loss: 0.354381, Acc: 0.904100\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 35\n",
      "[35/100] Loss: 0.365801, Acc: 0.899167\n",
      "[35/100] Loss: 0.368702, Acc: 0.899375\n",
      "[35/100] Loss: 0.372194, Acc: 0.899306\n",
      "[35/100] Loss: 0.372629, Acc: 0.898620\n",
      "[35/100] Loss: 0.371062, Acc: 0.899417\n",
      "[35/100] Loss: 0.371699, Acc: 0.898958\n",
      "Finish 35 epoch, Loss: 0.372387, Acc: 0.898717\n",
      "Test Loss: 0.352596, Acc: 0.904900\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 36\n",
      "[36/100] Loss: 0.367761, Acc: 0.897500\n",
      "[36/100] Loss: 0.370798, Acc: 0.897188\n",
      "[36/100] Loss: 0.367471, Acc: 0.899167\n",
      "[36/100] Loss: 0.369840, Acc: 0.899245\n",
      "[36/100] Loss: 0.368126, Acc: 0.899708\n",
      "[36/100] Loss: 0.369775, Acc: 0.899462\n",
      "Finish 36 epoch, Loss: 0.370498, Acc: 0.899217\n",
      "Test Loss: 0.350837, Acc: 0.905800\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 37\n",
      "[37/100] Loss: 0.366367, Acc: 0.902708\n",
      "[37/100] Loss: 0.372650, Acc: 0.898333\n",
      "[37/100] Loss: 0.369299, Acc: 0.899444\n",
      "[37/100] Loss: 0.369335, Acc: 0.899896\n",
      "[37/100] Loss: 0.367687, Acc: 0.900396\n",
      "[37/100] Loss: 0.367401, Acc: 0.899948\n",
      "Finish 37 epoch, Loss: 0.368688, Acc: 0.899500\n",
      "Test Loss: 0.349211, Acc: 0.906200\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 38\n",
      "[38/100] Loss: 0.379941, Acc: 0.894375\n",
      "[38/100] Loss: 0.366483, Acc: 0.899115\n",
      "[38/100] Loss: 0.370629, Acc: 0.897917\n",
      "[38/100] Loss: 0.367933, Acc: 0.900052\n",
      "[38/100] Loss: 0.368614, Acc: 0.899208\n",
      "[38/100] Loss: 0.367934, Acc: 0.899462\n",
      "Finish 38 epoch, Loss: 0.366941, Acc: 0.899933\n",
      "Test Loss: 0.347594, Acc: 0.906300\n",
      "Time:17.2 s\n",
      "\n",
      "**********\n",
      "epoch 39\n",
      "[39/100] Loss: 0.359890, Acc: 0.903438\n",
      "[39/100] Loss: 0.362577, Acc: 0.901250\n",
      "[39/100] Loss: 0.360887, Acc: 0.901701\n",
      "[39/100] Loss: 0.361525, Acc: 0.901224\n",
      "[39/100] Loss: 0.364656, Acc: 0.900521\n",
      "[39/100] Loss: 0.365298, Acc: 0.900365\n",
      "Finish 39 epoch, Loss: 0.365269, Acc: 0.900217\n",
      "Test Loss: 0.346167, Acc: 0.906400\n",
      "Time:20.9 s\n",
      "\n",
      "**********\n",
      "epoch 40\n",
      "[40/100] Loss: 0.365350, Acc: 0.899271\n",
      "[40/100] Loss: 0.365737, Acc: 0.899740\n",
      "[40/100] Loss: 0.364016, Acc: 0.899965\n",
      "[40/100] Loss: 0.365390, Acc: 0.899557\n",
      "[40/100] Loss: 0.363918, Acc: 0.900229\n",
      "[40/100] Loss: 0.363495, Acc: 0.900642\n",
      "Finish 40 epoch, Loss: 0.363654, Acc: 0.900533\n",
      "Test Loss: 0.344707, Acc: 0.906600\n",
      "Time:18.3 s\n",
      "\n",
      "**********\n",
      "epoch 41\n",
      "[41/100] Loss: 0.359803, Acc: 0.901875\n",
      "[41/100] Loss: 0.362099, Acc: 0.900833\n",
      "[41/100] Loss: 0.362929, Acc: 0.900799\n",
      "[41/100] Loss: 0.364452, Acc: 0.900312\n",
      "[41/100] Loss: 0.364326, Acc: 0.900625\n",
      "[41/100] Loss: 0.362123, Acc: 0.900833\n",
      "Finish 41 epoch, Loss: 0.362108, Acc: 0.900750\n",
      "Test Loss: 0.343347, Acc: 0.906700\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 42\n",
      "[42/100] Loss: 0.368356, Acc: 0.898854\n",
      "[42/100] Loss: 0.366925, Acc: 0.900885\n",
      "[42/100] Loss: 0.362816, Acc: 0.900833\n",
      "[42/100] Loss: 0.361045, Acc: 0.901979\n",
      "[42/100] Loss: 0.360521, Acc: 0.901583\n",
      "[42/100] Loss: 0.360687, Acc: 0.901476\n",
      "Finish 42 epoch, Loss: 0.360619, Acc: 0.901350\n",
      "Test Loss: 0.341941, Acc: 0.907400\n",
      "Time:17.7 s\n",
      "\n",
      "**********\n",
      "epoch 43\n",
      "[43/100] Loss: 0.361122, Acc: 0.903333\n",
      "[43/100] Loss: 0.359844, Acc: 0.902240\n",
      "[43/100] Loss: 0.359421, Acc: 0.902604\n",
      "[43/100] Loss: 0.353539, Acc: 0.903438\n",
      "[43/100] Loss: 0.356190, Acc: 0.902250\n",
      "[43/100] Loss: 0.359005, Acc: 0.901302\n",
      "Finish 43 epoch, Loss: 0.359168, Acc: 0.901383\n",
      "Test Loss: 0.340758, Acc: 0.907000\n",
      "Time:17.1 s\n",
      "\n",
      "**********\n",
      "epoch 44\n",
      "[44/100] Loss: 0.369715, Acc: 0.898229\n",
      "[44/100] Loss: 0.359847, Acc: 0.899479\n",
      "[44/100] Loss: 0.361317, Acc: 0.899340\n",
      "[44/100] Loss: 0.357432, Acc: 0.901120\n",
      "[44/100] Loss: 0.355224, Acc: 0.902542\n",
      "[44/100] Loss: 0.355874, Acc: 0.902569\n",
      "Finish 44 epoch, Loss: 0.357768, Acc: 0.901717\n",
      "Test Loss: 0.339518, Acc: 0.908100\n",
      "Time:17.6 s\n",
      "\n",
      "**********\n",
      "epoch 45\n",
      "[45/100] Loss: 0.367729, Acc: 0.899375\n",
      "[45/100] Loss: 0.361839, Acc: 0.901823\n",
      "[45/100] Loss: 0.358598, Acc: 0.902882\n",
      "[45/100] Loss: 0.357686, Acc: 0.903177\n",
      "[45/100] Loss: 0.359373, Acc: 0.902042\n",
      "[45/100] Loss: 0.356639, Acc: 0.902378\n",
      "Finish 45 epoch, Loss: 0.356414, Acc: 0.902150\n",
      "Test Loss: 0.338252, Acc: 0.908100\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 46\n",
      "[46/100] Loss: 0.346550, Acc: 0.906979\n",
      "[46/100] Loss: 0.350380, Acc: 0.903542\n",
      "[46/100] Loss: 0.352072, Acc: 0.903368\n",
      "[46/100] Loss: 0.352784, Acc: 0.903542\n",
      "[46/100] Loss: 0.352604, Acc: 0.902979\n",
      "[46/100] Loss: 0.354972, Acc: 0.902257\n",
      "Finish 46 epoch, Loss: 0.355118, Acc: 0.902183\n",
      "Test Loss: 0.337127, Acc: 0.908500\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 47\n",
      "[47/100] Loss: 0.353538, Acc: 0.905000\n",
      "[47/100] Loss: 0.354767, Acc: 0.903177\n",
      "[47/100] Loss: 0.352059, Acc: 0.903090\n",
      "[47/100] Loss: 0.354745, Acc: 0.902969\n",
      "[47/100] Loss: 0.356163, Acc: 0.902250\n",
      "[47/100] Loss: 0.354005, Acc: 0.902205\n",
      "Finish 47 epoch, Loss: 0.353854, Acc: 0.902550\n",
      "Test Loss: 0.335948, Acc: 0.908500\n",
      "Time:17.4 s\n",
      "\n",
      "**********\n",
      "epoch 48\n",
      "[48/100] Loss: 0.345945, Acc: 0.903750\n",
      "[48/100] Loss: 0.349216, Acc: 0.903646\n",
      "[48/100] Loss: 0.354168, Acc: 0.902708\n",
      "[48/100] Loss: 0.352241, Acc: 0.903047\n",
      "[48/100] Loss: 0.353058, Acc: 0.903125\n",
      "[48/100] Loss: 0.352889, Acc: 0.902951\n",
      "Finish 48 epoch, Loss: 0.352640, Acc: 0.903033\n",
      "Test Loss: 0.334872, Acc: 0.908700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:17.4 s\n",
      "\n",
      "**********\n",
      "epoch 49\n",
      "[49/100] Loss: 0.357041, Acc: 0.902396\n",
      "[49/100] Loss: 0.357104, Acc: 0.902188\n",
      "[49/100] Loss: 0.357457, Acc: 0.901285\n",
      "[49/100] Loss: 0.355793, Acc: 0.901432\n",
      "[49/100] Loss: 0.354926, Acc: 0.902271\n",
      "[49/100] Loss: 0.351357, Acc: 0.903177\n",
      "Finish 49 epoch, Loss: 0.351451, Acc: 0.903033\n",
      "Test Loss: 0.333915, Acc: 0.909100\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 50\n",
      "[50/100] Loss: 0.342911, Acc: 0.906875\n",
      "[50/100] Loss: 0.345451, Acc: 0.904271\n",
      "[50/100] Loss: 0.346953, Acc: 0.904444\n",
      "[50/100] Loss: 0.344793, Acc: 0.905156\n",
      "[50/100] Loss: 0.349179, Acc: 0.903563\n",
      "[50/100] Loss: 0.349879, Acc: 0.903403\n",
      "Finish 50 epoch, Loss: 0.350307, Acc: 0.903417\n",
      "Test Loss: 0.332861, Acc: 0.908800\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 51\n",
      "[51/100] Loss: 0.340070, Acc: 0.905625\n",
      "[51/100] Loss: 0.348517, Acc: 0.904479\n",
      "[51/100] Loss: 0.349517, Acc: 0.904757\n",
      "[51/100] Loss: 0.348001, Acc: 0.905234\n",
      "[51/100] Loss: 0.346901, Acc: 0.905333\n",
      "[51/100] Loss: 0.347878, Acc: 0.904323\n",
      "Finish 51 epoch, Loss: 0.349191, Acc: 0.903900\n",
      "Test Loss: 0.331916, Acc: 0.909100\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 52\n",
      "[52/100] Loss: 0.348887, Acc: 0.903854\n",
      "[52/100] Loss: 0.346675, Acc: 0.903333\n",
      "[52/100] Loss: 0.347301, Acc: 0.904687\n",
      "[52/100] Loss: 0.345915, Acc: 0.904635\n",
      "[52/100] Loss: 0.348373, Acc: 0.904021\n",
      "[52/100] Loss: 0.347794, Acc: 0.904062\n",
      "Finish 52 epoch, Loss: 0.348110, Acc: 0.903950\n",
      "Test Loss: 0.330974, Acc: 0.909300\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 53\n",
      "[53/100] Loss: 0.346519, Acc: 0.903750\n",
      "[53/100] Loss: 0.354067, Acc: 0.903073\n",
      "[53/100] Loss: 0.349303, Acc: 0.904340\n",
      "[53/100] Loss: 0.348353, Acc: 0.904115\n",
      "[53/100] Loss: 0.347636, Acc: 0.903792\n",
      "[53/100] Loss: 0.347012, Acc: 0.904132\n",
      "Finish 53 epoch, Loss: 0.347054, Acc: 0.904150\n",
      "Test Loss: 0.330024, Acc: 0.909700\n",
      "Time:17.2 s\n",
      "\n",
      "**********\n",
      "epoch 54\n",
      "[54/100] Loss: 0.343464, Acc: 0.907396\n",
      "[54/100] Loss: 0.340092, Acc: 0.906302\n",
      "[54/100] Loss: 0.340062, Acc: 0.905764\n",
      "[54/100] Loss: 0.343626, Acc: 0.905130\n",
      "[54/100] Loss: 0.344335, Acc: 0.904896\n",
      "[54/100] Loss: 0.346015, Acc: 0.904462\n",
      "Finish 54 epoch, Loss: 0.346022, Acc: 0.904483\n",
      "Test Loss: 0.329116, Acc: 0.909500\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 55\n",
      "[55/100] Loss: 0.348562, Acc: 0.903750\n",
      "[55/100] Loss: 0.345671, Acc: 0.905469\n",
      "[55/100] Loss: 0.344505, Acc: 0.905069\n",
      "[55/100] Loss: 0.345133, Acc: 0.904766\n",
      "[55/100] Loss: 0.346789, Acc: 0.904000\n",
      "[55/100] Loss: 0.346179, Acc: 0.904358\n",
      "Finish 55 epoch, Loss: 0.345031, Acc: 0.904667\n",
      "Test Loss: 0.328267, Acc: 0.910200\n",
      "Time:16.9 s\n",
      "\n",
      "**********\n",
      "epoch 56\n",
      "[56/100] Loss: 0.350260, Acc: 0.903438\n",
      "[56/100] Loss: 0.350127, Acc: 0.901250\n",
      "[56/100] Loss: 0.350442, Acc: 0.902222\n",
      "[56/100] Loss: 0.344978, Acc: 0.903854\n",
      "[56/100] Loss: 0.345445, Acc: 0.903896\n",
      "[56/100] Loss: 0.344020, Acc: 0.904983\n",
      "Finish 56 epoch, Loss: 0.344060, Acc: 0.904833\n",
      "Test Loss: 0.327362, Acc: 0.910400\n",
      "Time:16.5 s\n",
      "\n",
      "**********\n",
      "epoch 57\n",
      "[57/100] Loss: 0.338875, Acc: 0.904375\n",
      "[57/100] Loss: 0.340003, Acc: 0.905573\n",
      "[57/100] Loss: 0.344676, Acc: 0.904132\n",
      "[57/100] Loss: 0.343259, Acc: 0.904323\n",
      "[57/100] Loss: 0.342681, Acc: 0.904708\n",
      "[57/100] Loss: 0.342309, Acc: 0.905052\n",
      "Finish 57 epoch, Loss: 0.343116, Acc: 0.905050\n",
      "Test Loss: 0.326621, Acc: 0.910600\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 58\n",
      "[58/100] Loss: 0.347068, Acc: 0.906354\n",
      "[58/100] Loss: 0.345638, Acc: 0.904531\n",
      "[58/100] Loss: 0.346606, Acc: 0.904340\n",
      "[58/100] Loss: 0.346958, Acc: 0.903958\n",
      "[58/100] Loss: 0.343505, Acc: 0.904854\n",
      "[58/100] Loss: 0.341447, Acc: 0.905260\n",
      "Finish 58 epoch, Loss: 0.342188, Acc: 0.905217\n",
      "Test Loss: 0.325790, Acc: 0.911300\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 59\n",
      "[59/100] Loss: 0.345679, Acc: 0.905937\n",
      "[59/100] Loss: 0.349203, Acc: 0.903281\n",
      "[59/100] Loss: 0.351496, Acc: 0.902396\n",
      "[59/100] Loss: 0.347390, Acc: 0.903828\n",
      "[59/100] Loss: 0.344792, Acc: 0.904271\n",
      "[59/100] Loss: 0.342230, Acc: 0.904878\n",
      "Finish 59 epoch, Loss: 0.341305, Acc: 0.905333\n",
      "Test Loss: 0.325021, Acc: 0.911300\n",
      "Time:16.9 s\n",
      "\n",
      "**********\n",
      "epoch 60\n",
      "[60/100] Loss: 0.329089, Acc: 0.908646\n",
      "[60/100] Loss: 0.335736, Acc: 0.906198\n",
      "[60/100] Loss: 0.341777, Acc: 0.903958\n",
      "[60/100] Loss: 0.339194, Acc: 0.905443\n",
      "[60/100] Loss: 0.340238, Acc: 0.905875\n",
      "[60/100] Loss: 0.340575, Acc: 0.905660\n",
      "Finish 60 epoch, Loss: 0.340414, Acc: 0.905683\n",
      "Test Loss: 0.324285, Acc: 0.911300\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 61\n",
      "[61/100] Loss: 0.344222, Acc: 0.904062\n",
      "[61/100] Loss: 0.339446, Acc: 0.905885\n",
      "[61/100] Loss: 0.341595, Acc: 0.904167\n",
      "[61/100] Loss: 0.341211, Acc: 0.904922\n",
      "[61/100] Loss: 0.339368, Acc: 0.905396\n",
      "[61/100] Loss: 0.339166, Acc: 0.905885\n",
      "Finish 61 epoch, Loss: 0.339566, Acc: 0.905650\n",
      "Test Loss: 0.323645, Acc: 0.911900\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 62\n",
      "[62/100] Loss: 0.337361, Acc: 0.908125\n",
      "[62/100] Loss: 0.339479, Acc: 0.906823\n",
      "[62/100] Loss: 0.336774, Acc: 0.906007\n",
      "[62/100] Loss: 0.341924, Acc: 0.904609\n",
      "[62/100] Loss: 0.337715, Acc: 0.906458\n",
      "[62/100] Loss: 0.338986, Acc: 0.905885\n",
      "Finish 62 epoch, Loss: 0.338741, Acc: 0.906017\n",
      "Test Loss: 0.322845, Acc: 0.912000\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 63\n",
      "[63/100] Loss: 0.336178, Acc: 0.902292\n",
      "[63/100] Loss: 0.335546, Acc: 0.906146\n",
      "[63/100] Loss: 0.335317, Acc: 0.907743\n",
      "[63/100] Loss: 0.335369, Acc: 0.906484\n",
      "[63/100] Loss: 0.336183, Acc: 0.906500\n",
      "[63/100] Loss: 0.337467, Acc: 0.906163\n",
      "Finish 63 epoch, Loss: 0.337919, Acc: 0.906167\n",
      "Test Loss: 0.322125, Acc: 0.912000\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 64\n",
      "[64/100] Loss: 0.341558, Acc: 0.905729\n",
      "[64/100] Loss: 0.339062, Acc: 0.906979\n",
      "[64/100] Loss: 0.337621, Acc: 0.907951\n",
      "[64/100] Loss: 0.338897, Acc: 0.906693\n",
      "[64/100] Loss: 0.337262, Acc: 0.906521\n",
      "[64/100] Loss: 0.337480, Acc: 0.906441\n",
      "Finish 64 epoch, Loss: 0.337126, Acc: 0.906533\n",
      "Test Loss: 0.321377, Acc: 0.912500\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 65\n",
      "[65/100] Loss: 0.322605, Acc: 0.910312\n",
      "[65/100] Loss: 0.328940, Acc: 0.910781\n",
      "[65/100] Loss: 0.328565, Acc: 0.910694\n",
      "[65/100] Loss: 0.334281, Acc: 0.908047\n",
      "[65/100] Loss: 0.332664, Acc: 0.908458\n",
      "[65/100] Loss: 0.335019, Acc: 0.907031\n",
      "Finish 65 epoch, Loss: 0.336338, Acc: 0.906667\n",
      "Test Loss: 0.320741, Acc: 0.912300\n",
      "Time:16.5 s\n",
      "\n",
      "**********\n",
      "epoch 66\n",
      "[66/100] Loss: 0.332566, Acc: 0.907813\n",
      "[66/100] Loss: 0.335698, Acc: 0.906094\n",
      "[66/100] Loss: 0.334130, Acc: 0.906667\n",
      "[66/100] Loss: 0.334302, Acc: 0.906302\n",
      "[66/100] Loss: 0.333930, Acc: 0.906208\n",
      "[66/100] Loss: 0.336609, Acc: 0.906372\n",
      "Finish 66 epoch, Loss: 0.335584, Acc: 0.906783\n",
      "Test Loss: 0.320104, Acc: 0.912700\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 67\n",
      "[67/100] Loss: 0.339872, Acc: 0.903333\n",
      "[67/100] Loss: 0.343648, Acc: 0.902969\n",
      "[67/100] Loss: 0.338760, Acc: 0.905139\n",
      "[67/100] Loss: 0.336255, Acc: 0.906901\n",
      "[67/100] Loss: 0.334943, Acc: 0.907396\n",
      "[67/100] Loss: 0.335650, Acc: 0.906979\n",
      "Finish 67 epoch, Loss: 0.334836, Acc: 0.907183\n",
      "Test Loss: 0.319516, Acc: 0.912300\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 68\n",
      "[68/100] Loss: 0.340690, Acc: 0.904062\n",
      "[68/100] Loss: 0.341849, Acc: 0.903385\n",
      "[68/100] Loss: 0.337778, Acc: 0.905035\n",
      "[68/100] Loss: 0.336757, Acc: 0.906302\n",
      "[68/100] Loss: 0.335837, Acc: 0.906729\n",
      "[68/100] Loss: 0.333790, Acc: 0.907431\n",
      "Finish 68 epoch, Loss: 0.334111, Acc: 0.907433\n",
      "Test Loss: 0.318907, Acc: 0.913100\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 69\n",
      "[69/100] Loss: 0.338929, Acc: 0.906042\n",
      "[69/100] Loss: 0.339259, Acc: 0.904844\n",
      "[69/100] Loss: 0.335343, Acc: 0.906736\n",
      "[69/100] Loss: 0.334967, Acc: 0.907682\n",
      "[69/100] Loss: 0.332107, Acc: 0.908229\n",
      "[69/100] Loss: 0.334390, Acc: 0.907205\n",
      "Finish 69 epoch, Loss: 0.333401, Acc: 0.907450\n",
      "Test Loss: 0.318300, Acc: 0.912900\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 70\n",
      "[70/100] Loss: 0.333992, Acc: 0.908750\n",
      "[70/100] Loss: 0.334010, Acc: 0.908125\n",
      "[70/100] Loss: 0.331241, Acc: 0.908368\n",
      "[70/100] Loss: 0.331554, Acc: 0.908411\n",
      "[70/100] Loss: 0.331056, Acc: 0.908417\n",
      "[70/100] Loss: 0.331772, Acc: 0.908125\n",
      "Finish 70 epoch, Loss: 0.332695, Acc: 0.907733\n",
      "Test Loss: 0.317600, Acc: 0.913000\n",
      "Time:17.3 s\n",
      "\n",
      "**********\n",
      "epoch 71\n",
      "[71/100] Loss: 0.329080, Acc: 0.908750\n",
      "[71/100] Loss: 0.330024, Acc: 0.907708\n",
      "[71/100] Loss: 0.327653, Acc: 0.909028\n",
      "[71/100] Loss: 0.328862, Acc: 0.908594\n",
      "[71/100] Loss: 0.328655, Acc: 0.908833\n",
      "[71/100] Loss: 0.331614, Acc: 0.907969\n",
      "Finish 71 epoch, Loss: 0.332021, Acc: 0.908033\n",
      "Test Loss: 0.317122, Acc: 0.913100\n",
      "Time:17.4 s\n",
      "\n",
      "**********\n",
      "epoch 72\n",
      "[72/100] Loss: 0.323184, Acc: 0.913646\n",
      "[72/100] Loss: 0.326454, Acc: 0.911302\n",
      "[72/100] Loss: 0.329370, Acc: 0.909444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/100] Loss: 0.330253, Acc: 0.908620\n",
      "[72/100] Loss: 0.331255, Acc: 0.908146\n",
      "[72/100] Loss: 0.331242, Acc: 0.908125\n",
      "Finish 72 epoch, Loss: 0.331333, Acc: 0.908167\n",
      "Test Loss: 0.316535, Acc: 0.913500\n",
      "Time:17.7 s\n",
      "\n",
      "**********\n",
      "epoch 73\n",
      "[73/100] Loss: 0.337311, Acc: 0.904583\n",
      "[73/100] Loss: 0.337458, Acc: 0.906146\n",
      "[73/100] Loss: 0.333586, Acc: 0.907188\n",
      "[73/100] Loss: 0.332114, Acc: 0.907839\n",
      "[73/100] Loss: 0.330921, Acc: 0.908333\n",
      "[73/100] Loss: 0.329978, Acc: 0.908628\n",
      "Finish 73 epoch, Loss: 0.330704, Acc: 0.908233\n",
      "Test Loss: 0.315931, Acc: 0.913700\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 74\n",
      "[74/100] Loss: 0.332301, Acc: 0.906771\n",
      "[74/100] Loss: 0.329401, Acc: 0.908125\n",
      "[74/100] Loss: 0.326632, Acc: 0.909479\n",
      "[74/100] Loss: 0.328873, Acc: 0.908698\n",
      "[74/100] Loss: 0.328092, Acc: 0.908917\n",
      "[74/100] Loss: 0.329012, Acc: 0.908663\n",
      "Finish 74 epoch, Loss: 0.330051, Acc: 0.908300\n",
      "Test Loss: 0.315346, Acc: 0.913600\n",
      "Time:17.2 s\n",
      "\n",
      "**********\n",
      "epoch 75\n",
      "[75/100] Loss: 0.333188, Acc: 0.909583\n",
      "[75/100] Loss: 0.338020, Acc: 0.906146\n",
      "[75/100] Loss: 0.334641, Acc: 0.908264\n",
      "[75/100] Loss: 0.331754, Acc: 0.908073\n",
      "[75/100] Loss: 0.330636, Acc: 0.908479\n",
      "[75/100] Loss: 0.329843, Acc: 0.908611\n",
      "Finish 75 epoch, Loss: 0.329423, Acc: 0.908567\n",
      "Test Loss: 0.314825, Acc: 0.914000\n",
      "Time:17.8 s\n",
      "\n",
      "**********\n",
      "epoch 76\n",
      "[76/100] Loss: 0.313686, Acc: 0.911771\n",
      "[76/100] Loss: 0.318663, Acc: 0.910521\n",
      "[76/100] Loss: 0.319658, Acc: 0.911458\n",
      "[76/100] Loss: 0.325155, Acc: 0.909948\n",
      "[76/100] Loss: 0.327490, Acc: 0.909625\n",
      "[76/100] Loss: 0.328653, Acc: 0.908906\n",
      "Finish 76 epoch, Loss: 0.328811, Acc: 0.908767\n",
      "Test Loss: 0.314372, Acc: 0.914000\n",
      "Time:16.9 s\n",
      "\n",
      "**********\n",
      "epoch 77\n",
      "[77/100] Loss: 0.321328, Acc: 0.909583\n",
      "[77/100] Loss: 0.328526, Acc: 0.908021\n",
      "[77/100] Loss: 0.328444, Acc: 0.907778\n",
      "[77/100] Loss: 0.327588, Acc: 0.909062\n",
      "[77/100] Loss: 0.328747, Acc: 0.908542\n",
      "[77/100] Loss: 0.328277, Acc: 0.909062\n",
      "Finish 77 epoch, Loss: 0.328199, Acc: 0.909017\n",
      "Test Loss: 0.313870, Acc: 0.914300\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 78\n",
      "[78/100] Loss: 0.318866, Acc: 0.910208\n",
      "[78/100] Loss: 0.323400, Acc: 0.908906\n",
      "[78/100] Loss: 0.324920, Acc: 0.909028\n",
      "[78/100] Loss: 0.326481, Acc: 0.908880\n",
      "[78/100] Loss: 0.328783, Acc: 0.908167\n",
      "[78/100] Loss: 0.328780, Acc: 0.908802\n",
      "Finish 78 epoch, Loss: 0.327609, Acc: 0.909300\n",
      "Test Loss: 0.313372, Acc: 0.914400\n",
      "Time:17.1 s\n",
      "\n",
      "**********\n",
      "epoch 79\n",
      "[79/100] Loss: 0.330503, Acc: 0.907188\n",
      "[79/100] Loss: 0.332241, Acc: 0.908333\n",
      "[79/100] Loss: 0.327901, Acc: 0.910347\n",
      "[79/100] Loss: 0.326564, Acc: 0.909687\n",
      "[79/100] Loss: 0.327214, Acc: 0.909521\n",
      "[79/100] Loss: 0.326026, Acc: 0.910000\n",
      "Finish 79 epoch, Loss: 0.327020, Acc: 0.909333\n",
      "Test Loss: 0.312970, Acc: 0.914400\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 80\n",
      "[80/100] Loss: 0.330709, Acc: 0.909479\n",
      "[80/100] Loss: 0.328469, Acc: 0.909167\n",
      "[80/100] Loss: 0.329417, Acc: 0.907847\n",
      "[80/100] Loss: 0.330803, Acc: 0.907813\n",
      "[80/100] Loss: 0.330204, Acc: 0.908417\n",
      "[80/100] Loss: 0.328475, Acc: 0.908906\n",
      "Finish 80 epoch, Loss: 0.326456, Acc: 0.909517\n",
      "Test Loss: 0.312466, Acc: 0.914700\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 81\n",
      "[81/100] Loss: 0.334520, Acc: 0.908021\n",
      "[81/100] Loss: 0.332330, Acc: 0.906615\n",
      "[81/100] Loss: 0.331014, Acc: 0.907951\n",
      "[81/100] Loss: 0.326961, Acc: 0.909531\n",
      "[81/100] Loss: 0.326083, Acc: 0.909229\n",
      "[81/100] Loss: 0.325804, Acc: 0.909479\n",
      "Finish 81 epoch, Loss: 0.325886, Acc: 0.909617\n",
      "Test Loss: 0.311917, Acc: 0.914900\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 82\n",
      "[82/100] Loss: 0.314293, Acc: 0.912083\n",
      "[82/100] Loss: 0.323443, Acc: 0.910729\n",
      "[82/100] Loss: 0.319446, Acc: 0.912361\n",
      "[82/100] Loss: 0.320678, Acc: 0.911615\n",
      "[82/100] Loss: 0.324857, Acc: 0.910833\n",
      "[82/100] Loss: 0.324920, Acc: 0.910677\n",
      "Finish 82 epoch, Loss: 0.325338, Acc: 0.909983\n",
      "Test Loss: 0.311537, Acc: 0.914600\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 83\n",
      "[83/100] Loss: 0.333202, Acc: 0.908854\n",
      "[83/100] Loss: 0.336608, Acc: 0.908646\n",
      "[83/100] Loss: 0.328229, Acc: 0.909583\n",
      "[83/100] Loss: 0.327583, Acc: 0.909531\n",
      "[83/100] Loss: 0.326489, Acc: 0.909750\n",
      "[83/100] Loss: 0.324614, Acc: 0.910208\n",
      "Finish 83 epoch, Loss: 0.324778, Acc: 0.909983\n",
      "Test Loss: 0.311084, Acc: 0.915100\n",
      "Time:16.8 s\n",
      "\n",
      "**********\n",
      "epoch 84\n",
      "[84/100] Loss: 0.323045, Acc: 0.911979\n",
      "[84/100] Loss: 0.324160, Acc: 0.911615\n",
      "[84/100] Loss: 0.329972, Acc: 0.909132\n",
      "[84/100] Loss: 0.328723, Acc: 0.908698\n",
      "[84/100] Loss: 0.325920, Acc: 0.909563\n",
      "[84/100] Loss: 0.324371, Acc: 0.910000\n",
      "Finish 84 epoch, Loss: 0.324266, Acc: 0.910083\n",
      "Test Loss: 0.310542, Acc: 0.915200\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 85\n",
      "[85/100] Loss: 0.321299, Acc: 0.910833\n",
      "[85/100] Loss: 0.323561, Acc: 0.909948\n",
      "[85/100] Loss: 0.324101, Acc: 0.908993\n",
      "[85/100] Loss: 0.324048, Acc: 0.909427\n",
      "[85/100] Loss: 0.323449, Acc: 0.909875\n",
      "[85/100] Loss: 0.323649, Acc: 0.909948\n",
      "Finish 85 epoch, Loss: 0.323745, Acc: 0.910083\n",
      "Test Loss: 0.310205, Acc: 0.915200\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 86\n",
      "[86/100] Loss: 0.324413, Acc: 0.910208\n",
      "[86/100] Loss: 0.328685, Acc: 0.909010\n",
      "[86/100] Loss: 0.325212, Acc: 0.910069\n",
      "[86/100] Loss: 0.322810, Acc: 0.910443\n",
      "[86/100] Loss: 0.324426, Acc: 0.909875\n",
      "[86/100] Loss: 0.322957, Acc: 0.910330\n",
      "Finish 86 epoch, Loss: 0.323227, Acc: 0.910400\n",
      "Test Loss: 0.309747, Acc: 0.915400\n",
      "Time:16.9 s\n",
      "\n",
      "**********\n",
      "epoch 87\n",
      "[87/100] Loss: 0.322553, Acc: 0.909271\n",
      "[87/100] Loss: 0.324686, Acc: 0.907552\n",
      "[87/100] Loss: 0.325553, Acc: 0.909062\n",
      "[87/100] Loss: 0.324290, Acc: 0.910417\n",
      "[87/100] Loss: 0.323850, Acc: 0.910604\n",
      "[87/100] Loss: 0.323167, Acc: 0.910312\n",
      "Finish 87 epoch, Loss: 0.322731, Acc: 0.910650\n",
      "Test Loss: 0.309333, Acc: 0.915300\n",
      "Time:16.7 s\n",
      "\n",
      "**********\n",
      "epoch 88\n",
      "[88/100] Loss: 0.314032, Acc: 0.911354\n",
      "[88/100] Loss: 0.323224, Acc: 0.910573\n",
      "[88/100] Loss: 0.322869, Acc: 0.911319\n",
      "[88/100] Loss: 0.322385, Acc: 0.911406\n",
      "[88/100] Loss: 0.322670, Acc: 0.910479\n",
      "[88/100] Loss: 0.322387, Acc: 0.910625\n",
      "Finish 88 epoch, Loss: 0.322214, Acc: 0.910733\n",
      "Test Loss: 0.308957, Acc: 0.915300\n",
      "Time:16.6 s\n",
      "\n",
      "**********\n",
      "epoch 89\n",
      "[89/100] Loss: 0.315245, Acc: 0.909271\n",
      "[89/100] Loss: 0.316447, Acc: 0.912240\n",
      "[89/100] Loss: 0.325432, Acc: 0.908993\n",
      "[89/100] Loss: 0.322975, Acc: 0.910312\n",
      "[89/100] Loss: 0.321679, Acc: 0.910667\n",
      "[89/100] Loss: 0.321264, Acc: 0.910712\n",
      "Finish 89 epoch, Loss: 0.321742, Acc: 0.910533\n",
      "Test Loss: 0.308553, Acc: 0.915400\n",
      "Time:17.1 s\n",
      "\n",
      "**********\n",
      "epoch 90\n",
      "[90/100] Loss: 0.317248, Acc: 0.911875\n",
      "[90/100] Loss: 0.317533, Acc: 0.911823\n",
      "[90/100] Loss: 0.319792, Acc: 0.910660\n",
      "[90/100] Loss: 0.320617, Acc: 0.911250\n",
      "[90/100] Loss: 0.322767, Acc: 0.910542\n",
      "[90/100] Loss: 0.321381, Acc: 0.911111\n",
      "Finish 90 epoch, Loss: 0.321253, Acc: 0.910900\n",
      "Test Loss: 0.308193, Acc: 0.915600\n",
      "Time:17.9 s\n",
      "\n",
      "**********\n",
      "epoch 91\n",
      "[91/100] Loss: 0.326114, Acc: 0.909792\n",
      "[91/100] Loss: 0.323048, Acc: 0.910885\n",
      "[91/100] Loss: 0.322930, Acc: 0.910208\n",
      "[91/100] Loss: 0.322371, Acc: 0.910130\n",
      "[91/100] Loss: 0.322305, Acc: 0.910667\n",
      "[91/100] Loss: 0.321110, Acc: 0.911250\n",
      "Finish 91 epoch, Loss: 0.320786, Acc: 0.910933\n",
      "Test Loss: 0.307720, Acc: 0.915700\n",
      "Time:17.0 s\n",
      "\n",
      "**********\n",
      "epoch 92\n",
      "[92/100] Loss: 0.321336, Acc: 0.911667\n",
      "[92/100] Loss: 0.319593, Acc: 0.912083\n",
      "[92/100] Loss: 0.320030, Acc: 0.911042\n",
      "[92/100] Loss: 0.318676, Acc: 0.912005\n",
      "[92/100] Loss: 0.321780, Acc: 0.910833\n",
      "[92/100] Loss: 0.320861, Acc: 0.911042\n",
      "Finish 92 epoch, Loss: 0.320306, Acc: 0.911133\n",
      "Test Loss: 0.307358, Acc: 0.915700\n",
      "Time:22.3 s\n",
      "\n",
      "**********\n",
      "epoch 93\n",
      "[93/100] Loss: 0.329340, Acc: 0.908333\n",
      "[93/100] Loss: 0.321601, Acc: 0.911302\n",
      "[93/100] Loss: 0.321479, Acc: 0.911319\n",
      "[93/100] Loss: 0.317950, Acc: 0.912396\n",
      "[93/100] Loss: 0.319106, Acc: 0.911542\n",
      "[93/100] Loss: 0.320035, Acc: 0.911076\n",
      "Finish 93 epoch, Loss: 0.319852, Acc: 0.911217\n",
      "Test Loss: 0.307084, Acc: 0.915400\n",
      "Time:19.1 s\n",
      "\n",
      "**********\n",
      "epoch 94\n",
      "[94/100] Loss: 0.317775, Acc: 0.913750\n",
      "[94/100] Loss: 0.312207, Acc: 0.913698\n",
      "[94/100] Loss: 0.313888, Acc: 0.913229\n",
      "[94/100] Loss: 0.314710, Acc: 0.911901\n",
      "[94/100] Loss: 0.316923, Acc: 0.911542\n",
      "[94/100] Loss: 0.319749, Acc: 0.910972\n",
      "Finish 94 epoch, Loss: 0.319399, Acc: 0.911067\n",
      "Test Loss: 0.306642, Acc: 0.915500\n",
      "Time:18.0 s\n",
      "\n",
      "**********\n",
      "epoch 95\n",
      "[95/100] Loss: 0.322493, Acc: 0.912188\n",
      "[95/100] Loss: 0.317832, Acc: 0.912865\n",
      "[95/100] Loss: 0.318411, Acc: 0.911979\n",
      "[95/100] Loss: 0.318640, Acc: 0.912682\n",
      "[95/100] Loss: 0.319483, Acc: 0.912521\n",
      "[95/100] Loss: 0.319110, Acc: 0.911684\n",
      "Finish 95 epoch, Loss: 0.318959, Acc: 0.911500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.306254, Acc: 0.915800\n",
      "Time:17.8 s\n",
      "\n",
      "**********\n",
      "epoch 96\n",
      "[96/100] Loss: 0.317030, Acc: 0.912917\n",
      "[96/100] Loss: 0.319376, Acc: 0.911667\n",
      "[96/100] Loss: 0.320567, Acc: 0.910729\n",
      "[96/100] Loss: 0.316608, Acc: 0.911328\n",
      "[96/100] Loss: 0.318847, Acc: 0.911021\n",
      "[96/100] Loss: 0.318134, Acc: 0.911563\n",
      "Finish 96 epoch, Loss: 0.318517, Acc: 0.911517\n",
      "Test Loss: 0.305904, Acc: 0.916100\n",
      "Time:17.2 s\n",
      "\n",
      "**********\n",
      "epoch 97\n",
      "[97/100] Loss: 0.312580, Acc: 0.914062\n",
      "[97/100] Loss: 0.315009, Acc: 0.911302\n",
      "[97/100] Loss: 0.314533, Acc: 0.911389\n",
      "[97/100] Loss: 0.313742, Acc: 0.912161\n",
      "[97/100] Loss: 0.316391, Acc: 0.911625\n",
      "[97/100] Loss: 0.318328, Acc: 0.911285\n",
      "Finish 97 epoch, Loss: 0.318088, Acc: 0.911600\n",
      "Test Loss: 0.305573, Acc: 0.915500\n",
      "Time:17.8 s\n",
      "\n",
      "**********\n",
      "epoch 98\n",
      "[98/100] Loss: 0.309891, Acc: 0.910729\n",
      "[98/100] Loss: 0.317463, Acc: 0.911406\n",
      "[98/100] Loss: 0.318615, Acc: 0.911632\n",
      "[98/100] Loss: 0.318083, Acc: 0.912292\n",
      "[98/100] Loss: 0.318435, Acc: 0.911687\n",
      "[98/100] Loss: 0.317190, Acc: 0.911701\n",
      "Finish 98 epoch, Loss: 0.317673, Acc: 0.911633\n",
      "Test Loss: 0.305238, Acc: 0.915600\n",
      "Time:21.2 s\n",
      "\n",
      "**********\n",
      "epoch 99\n",
      "[99/100] Loss: 0.308105, Acc: 0.916354\n",
      "[99/100] Loss: 0.312354, Acc: 0.914219\n",
      "[99/100] Loss: 0.315224, Acc: 0.911806\n",
      "[99/100] Loss: 0.319296, Acc: 0.911380\n",
      "[99/100] Loss: 0.319238, Acc: 0.911896\n",
      "[99/100] Loss: 0.317116, Acc: 0.912205\n",
      "Finish 99 epoch, Loss: 0.317243, Acc: 0.912033\n",
      "Test Loss: 0.304974, Acc: 0.915900\n",
      "Time:19.3 s\n",
      "\n",
      "**********\n",
      "epoch 100\n",
      "[100/100] Loss: 0.326832, Acc: 0.909792\n",
      "[100/100] Loss: 0.324382, Acc: 0.910521\n",
      "[100/100] Loss: 0.317399, Acc: 0.911146\n",
      "[100/100] Loss: 0.317932, Acc: 0.911849\n",
      "[100/100] Loss: 0.319338, Acc: 0.911604\n",
      "[100/100] Loss: 0.317333, Acc: 0.912118\n",
      "Finish 100 epoch, Loss: 0.316831, Acc: 0.912017\n",
      "Test Loss: 0.304622, Acc: 0.916100\n",
      "Time:18.8 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "\n",
    "    print('*' * 10)\n",
    "\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    running_acc = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "\n",
    "        img, label = data\n",
    "\n",
    "        img = img.view(img.size(0), -1)  # 将图片展开成 28x28\n",
    "\n",
    "        if use_gpu:\n",
    "\n",
    "            img = Variable(img).cuda()\n",
    "\n",
    "            label = Variable(label).cuda()\n",
    "\n",
    "        else:\n",
    "\n",
    "            img = Variable(img)\n",
    "\n",
    "            label = Variable(label)\n",
    "\n",
    "        # 向前传播\n",
    "\n",
    "        out = model(img)\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        num_correct = (pred == label).sum()\n",
    "\n",
    "        running_acc += num_correct.item()\n",
    "\n",
    "        # 向后传播\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        if i % 300 == 0:\n",
    "\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "\n",
    "                running_acc / (batch_size * i)))\n",
    "\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n",
    "\n",
    "            train_dataset))))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0.\n",
    "\n",
    "    eval_acc = 0.\n",
    "\n",
    "    for data in test_loader:\n",
    "\n",
    "        img, label = data\n",
    "\n",
    "        img = img.view(img.size(0), -1)\n",
    "\n",
    "        if use_gpu:\n",
    "\n",
    "            img = Variable(img, volatile=True).cuda()\n",
    "\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "\n",
    "        else:\n",
    "\n",
    "            img = Variable(img, volatile=True)\n",
    "\n",
    "            label = Variable(label, volatile=True)\n",
    "\n",
    "        out = model(img)\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        eval_loss += loss.item() * label.size(0)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        num_correct = (pred == label).sum()\n",
    "\n",
    "        eval_acc += num_correct.item()\n",
    "\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "\n",
    "        test_dataset)), eval_acc / (len(test_dataset))))\n",
    "\n",
    "    print('Time:{:.1f} s'.format(time.time() - since))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "torch.save(model.state_dict(), './logstic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

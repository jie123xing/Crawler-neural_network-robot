{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "num_epoches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练集 MNIST 手写数字训练集\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义简单的前馈神经网络\n",
    "\n",
    "class Neuralnetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "\n",
    "        super(Neuralnetwork, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neuralnetwork(28 * 28, 300, 100, 10)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n",
      "[1/50] Loss: 0.392620, Acc: 0.888958\n",
      "[1/50] Loss: 0.394535, Acc: 0.887708\n",
      "[1/50] Loss: 0.383305, Acc: 0.890764\n",
      "[1/50] Loss: 0.376706, Acc: 0.892474\n",
      "[1/50] Loss: 0.371869, Acc: 0.893813\n",
      "[1/50] Loss: 0.365297, Acc: 0.896111\n",
      "Finish 1 epoch, Loss: 0.363977, Acc: 0.896533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:87: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "I:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:89: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.325940, Acc: 0.905800\n",
      "\n",
      "epoch 2\n",
      "**********\n",
      "[2/50] Loss: 0.333252, Acc: 0.906146\n",
      "[2/50] Loss: 0.334839, Acc: 0.905365\n",
      "[2/50] Loss: 0.329931, Acc: 0.906181\n",
      "[2/50] Loss: 0.329324, Acc: 0.906042\n",
      "[2/50] Loss: 0.329295, Acc: 0.906646\n",
      "[2/50] Loss: 0.325630, Acc: 0.907153\n",
      "Finish 2 epoch, Loss: 0.325682, Acc: 0.907350\n",
      "Test Loss: 0.304571, Acc: 0.913700\n",
      "\n",
      "epoch 3\n",
      "**********\n",
      "[3/50] Loss: 0.316526, Acc: 0.906667\n",
      "[3/50] Loss: 0.308466, Acc: 0.911979\n",
      "[3/50] Loss: 0.308252, Acc: 0.912431\n",
      "[3/50] Loss: 0.308161, Acc: 0.912656\n",
      "[3/50] Loss: 0.309345, Acc: 0.912167\n",
      "[3/50] Loss: 0.308709, Acc: 0.912604\n",
      "Finish 3 epoch, Loss: 0.307819, Acc: 0.912867\n",
      "Test Loss: 0.294732, Acc: 0.917100\n",
      "\n",
      "epoch 4\n",
      "**********\n",
      "[4/50] Loss: 0.295222, Acc: 0.916875\n",
      "[4/50] Loss: 0.292770, Acc: 0.916562\n",
      "[4/50] Loss: 0.298080, Acc: 0.916181\n",
      "[4/50] Loss: 0.296866, Acc: 0.916250\n",
      "[4/50] Loss: 0.297499, Acc: 0.916292\n",
      "[4/50] Loss: 0.298635, Acc: 0.915260\n",
      "Finish 4 epoch, Loss: 0.297450, Acc: 0.915483\n",
      "Test Loss: 0.286208, Acc: 0.918500\n",
      "\n",
      "epoch 5\n",
      "**********\n",
      "[5/50] Loss: 0.300850, Acc: 0.912708\n",
      "[5/50] Loss: 0.299526, Acc: 0.915469\n",
      "[5/50] Loss: 0.296718, Acc: 0.915868\n",
      "[5/50] Loss: 0.295441, Acc: 0.916979\n",
      "[5/50] Loss: 0.292362, Acc: 0.918104\n",
      "[5/50] Loss: 0.289905, Acc: 0.918056\n",
      "Finish 5 epoch, Loss: 0.290047, Acc: 0.917800\n",
      "Test Loss: 0.283007, Acc: 0.920500\n",
      "\n",
      "epoch 6\n",
      "**********\n",
      "[6/50] Loss: 0.275147, Acc: 0.922604\n",
      "[6/50] Loss: 0.280508, Acc: 0.920729\n",
      "[6/50] Loss: 0.285066, Acc: 0.920764\n",
      "[6/50] Loss: 0.285302, Acc: 0.920286\n",
      "[6/50] Loss: 0.283868, Acc: 0.920250\n",
      "[6/50] Loss: 0.285765, Acc: 0.919861\n",
      "Finish 6 epoch, Loss: 0.284862, Acc: 0.920067\n",
      "Test Loss: 0.278586, Acc: 0.921000\n",
      "\n",
      "epoch 7\n",
      "**********\n",
      "[7/50] Loss: 0.287170, Acc: 0.922396\n",
      "[7/50] Loss: 0.275298, Acc: 0.923958\n",
      "[7/50] Loss: 0.280656, Acc: 0.922014\n",
      "[7/50] Loss: 0.280713, Acc: 0.921432\n",
      "[7/50] Loss: 0.280959, Acc: 0.921063\n",
      "[7/50] Loss: 0.280163, Acc: 0.921302\n",
      "Finish 7 epoch, Loss: 0.280080, Acc: 0.921100\n",
      "Test Loss: 0.275348, Acc: 0.922200\n",
      "\n",
      "epoch 8\n",
      "**********\n",
      "[8/50] Loss: 0.257025, Acc: 0.924167\n",
      "[8/50] Loss: 0.264960, Acc: 0.924740\n",
      "[8/50] Loss: 0.269962, Acc: 0.924028\n",
      "[8/50] Loss: 0.274336, Acc: 0.923411\n",
      "[8/50] Loss: 0.276995, Acc: 0.922312\n",
      "[8/50] Loss: 0.277890, Acc: 0.921788\n",
      "Finish 8 epoch, Loss: 0.276953, Acc: 0.922250\n",
      "Test Loss: 0.272094, Acc: 0.923500\n",
      "\n",
      "epoch 9\n",
      "**********\n",
      "[9/50] Loss: 0.285030, Acc: 0.919375\n",
      "[9/50] Loss: 0.276353, Acc: 0.922500\n",
      "[9/50] Loss: 0.273591, Acc: 0.923021\n",
      "[9/50] Loss: 0.274239, Acc: 0.922682\n",
      "[9/50] Loss: 0.274896, Acc: 0.922542\n",
      "[9/50] Loss: 0.275012, Acc: 0.922188\n",
      "Finish 9 epoch, Loss: 0.274435, Acc: 0.922517\n",
      "Test Loss: 0.275074, Acc: 0.921400\n",
      "\n",
      "epoch 10\n",
      "**********\n",
      "[10/50] Loss: 0.273439, Acc: 0.924896\n",
      "[10/50] Loss: 0.277612, Acc: 0.922865\n",
      "[10/50] Loss: 0.269843, Acc: 0.925312\n",
      "[10/50] Loss: 0.269923, Acc: 0.925078\n",
      "[10/50] Loss: 0.271343, Acc: 0.924188\n",
      "[10/50] Loss: 0.272528, Acc: 0.923698\n",
      "Finish 10 epoch, Loss: 0.272005, Acc: 0.924000\n",
      "Test Loss: 0.273976, Acc: 0.921900\n",
      "\n",
      "epoch 11\n",
      "**********\n",
      "[11/50] Loss: 0.272780, Acc: 0.922708\n",
      "[11/50] Loss: 0.272024, Acc: 0.923021\n",
      "[11/50] Loss: 0.269882, Acc: 0.924722\n",
      "[11/50] Loss: 0.268349, Acc: 0.924687\n",
      "[11/50] Loss: 0.268299, Acc: 0.924854\n",
      "[11/50] Loss: 0.267953, Acc: 0.924740\n",
      "Finish 11 epoch, Loss: 0.269365, Acc: 0.924583\n",
      "Test Loss: 0.274770, Acc: 0.921700\n",
      "\n",
      "epoch 12\n",
      "**********\n",
      "[12/50] Loss: 0.269551, Acc: 0.923229\n",
      "[12/50] Loss: 0.268911, Acc: 0.924010\n",
      "[12/50] Loss: 0.264409, Acc: 0.925278\n",
      "[12/50] Loss: 0.266888, Acc: 0.924531\n",
      "[12/50] Loss: 0.266893, Acc: 0.924396\n",
      "[12/50] Loss: 0.268584, Acc: 0.924306\n",
      "Finish 12 epoch, Loss: 0.267754, Acc: 0.924683\n",
      "Test Loss: 0.271054, Acc: 0.922300\n",
      "\n",
      "epoch 13\n",
      "**********\n",
      "[13/50] Loss: 0.261610, Acc: 0.927292\n",
      "[13/50] Loss: 0.260098, Acc: 0.927865\n",
      "[13/50] Loss: 0.261358, Acc: 0.926667\n",
      "[13/50] Loss: 0.267446, Acc: 0.925625\n",
      "[13/50] Loss: 0.267680, Acc: 0.925687\n",
      "[13/50] Loss: 0.266334, Acc: 0.925990\n",
      "Finish 13 epoch, Loss: 0.266253, Acc: 0.925933\n",
      "Test Loss: 0.272620, Acc: 0.921600\n",
      "\n",
      "epoch 14\n",
      "**********\n",
      "[14/50] Loss: 0.258222, Acc: 0.927604\n",
      "[14/50] Loss: 0.257247, Acc: 0.928177\n",
      "[14/50] Loss: 0.262378, Acc: 0.927813\n",
      "[14/50] Loss: 0.263062, Acc: 0.927057\n",
      "[14/50] Loss: 0.262063, Acc: 0.927646\n",
      "[14/50] Loss: 0.264611, Acc: 0.926510\n",
      "Finish 14 epoch, Loss: 0.264628, Acc: 0.926383\n",
      "Test Loss: 0.267518, Acc: 0.924600\n",
      "\n",
      "epoch 15\n",
      "**********\n",
      "[15/50] Loss: 0.255332, Acc: 0.926146\n",
      "[15/50] Loss: 0.255041, Acc: 0.927865\n",
      "[15/50] Loss: 0.261312, Acc: 0.926389\n",
      "[15/50] Loss: 0.263924, Acc: 0.925677\n",
      "[15/50] Loss: 0.263541, Acc: 0.926354\n",
      "[15/50] Loss: 0.264409, Acc: 0.926354\n",
      "Finish 15 epoch, Loss: 0.263621, Acc: 0.926600\n",
      "Test Loss: 0.271218, Acc: 0.921800\n",
      "\n",
      "epoch 16\n",
      "**********\n",
      "[16/50] Loss: 0.262471, Acc: 0.928958\n",
      "[16/50] Loss: 0.261972, Acc: 0.928125\n",
      "[16/50] Loss: 0.261874, Acc: 0.927049\n",
      "[16/50] Loss: 0.261798, Acc: 0.926771\n",
      "[16/50] Loss: 0.262828, Acc: 0.926792\n",
      "[16/50] Loss: 0.261723, Acc: 0.926510\n",
      "Finish 16 epoch, Loss: 0.262255, Acc: 0.926467\n",
      "Test Loss: 0.269770, Acc: 0.924400\n",
      "\n",
      "epoch 17\n",
      "**********\n",
      "[17/50] Loss: 0.249540, Acc: 0.928021\n",
      "[17/50] Loss: 0.255756, Acc: 0.926771\n",
      "[17/50] Loss: 0.259087, Acc: 0.925868\n",
      "[17/50] Loss: 0.255730, Acc: 0.927448\n",
      "[17/50] Loss: 0.256654, Acc: 0.927271\n",
      "[17/50] Loss: 0.259946, Acc: 0.926753\n",
      "Finish 17 epoch, Loss: 0.260592, Acc: 0.926700\n",
      "Test Loss: 0.272782, Acc: 0.922000\n",
      "\n",
      "epoch 18\n",
      "**********\n",
      "[18/50] Loss: 0.250296, Acc: 0.929167\n",
      "[18/50] Loss: 0.251955, Acc: 0.928698\n",
      "[18/50] Loss: 0.254589, Acc: 0.927569\n",
      "[18/50] Loss: 0.256456, Acc: 0.928073\n",
      "[18/50] Loss: 0.257945, Acc: 0.928000\n",
      "[18/50] Loss: 0.260796, Acc: 0.927292\n",
      "Finish 18 epoch, Loss: 0.260060, Acc: 0.927517\n",
      "Test Loss: 0.268446, Acc: 0.921900\n",
      "\n",
      "epoch 19\n",
      "**********\n",
      "[19/50] Loss: 0.257256, Acc: 0.930208\n",
      "[19/50] Loss: 0.259938, Acc: 0.928750\n",
      "[19/50] Loss: 0.254928, Acc: 0.929410\n",
      "[19/50] Loss: 0.257988, Acc: 0.928724\n",
      "[19/50] Loss: 0.258221, Acc: 0.928333\n",
      "[19/50] Loss: 0.257874, Acc: 0.928281\n",
      "Finish 19 epoch, Loss: 0.258655, Acc: 0.927883\n",
      "Test Loss: 0.273438, Acc: 0.921300\n",
      "\n",
      "epoch 20\n",
      "**********\n",
      "[20/50] Loss: 0.262712, Acc: 0.925312\n",
      "[20/50] Loss: 0.258570, Acc: 0.926979\n",
      "[20/50] Loss: 0.262838, Acc: 0.927604\n",
      "[20/50] Loss: 0.263292, Acc: 0.926875\n",
      "[20/50] Loss: 0.259065, Acc: 0.927604\n",
      "[20/50] Loss: 0.258993, Acc: 0.927969\n",
      "Finish 20 epoch, Loss: 0.258699, Acc: 0.927967\n",
      "Test Loss: 0.269358, Acc: 0.924700\n",
      "\n",
      "epoch 21\n",
      "**********\n",
      "[21/50] Loss: 0.242746, Acc: 0.931250\n",
      "[21/50] Loss: 0.248124, Acc: 0.930469\n",
      "[21/50] Loss: 0.254322, Acc: 0.928299\n",
      "[21/50] Loss: 0.254310, Acc: 0.928724\n",
      "[21/50] Loss: 0.255805, Acc: 0.929167\n",
      "[21/50] Loss: 0.257697, Acc: 0.929010\n",
      "Finish 21 epoch, Loss: 0.257414, Acc: 0.928983\n",
      "Test Loss: 0.273253, Acc: 0.921800\n",
      "\n",
      "epoch 22\n",
      "**********\n",
      "[22/50] Loss: 0.273195, Acc: 0.923021\n",
      "[22/50] Loss: 0.265162, Acc: 0.926615\n",
      "[22/50] Loss: 0.262587, Acc: 0.927465\n",
      "[22/50] Loss: 0.256346, Acc: 0.928802\n",
      "[22/50] Loss: 0.255935, Acc: 0.928833\n",
      "[22/50] Loss: 0.255940, Acc: 0.928872\n",
      "Finish 22 epoch, Loss: 0.256165, Acc: 0.928750\n",
      "Test Loss: 0.272500, Acc: 0.923600\n",
      "\n",
      "epoch 23\n",
      "**********\n",
      "[23/50] Loss: 0.253759, Acc: 0.931146\n",
      "[23/50] Loss: 0.253695, Acc: 0.929375\n",
      "[23/50] Loss: 0.250248, Acc: 0.930799\n",
      "[23/50] Loss: 0.254267, Acc: 0.930130\n",
      "[23/50] Loss: 0.253960, Acc: 0.929729\n",
      "[23/50] Loss: 0.255759, Acc: 0.928819\n",
      "Finish 23 epoch, Loss: 0.255638, Acc: 0.928950\n",
      "Test Loss: 0.272786, Acc: 0.923500\n",
      "\n",
      "epoch 24\n",
      "**********\n",
      "[24/50] Loss: 0.251815, Acc: 0.930521\n",
      "[24/50] Loss: 0.254259, Acc: 0.930312\n",
      "[24/50] Loss: 0.256603, Acc: 0.928646\n",
      "[24/50] Loss: 0.254118, Acc: 0.928906\n",
      "[24/50] Loss: 0.255546, Acc: 0.929042\n",
      "[24/50] Loss: 0.255405, Acc: 0.928802\n",
      "Finish 24 epoch, Loss: 0.254568, Acc: 0.928883\n",
      "Test Loss: 0.267462, Acc: 0.924000\n",
      "\n",
      "epoch 25\n",
      "**********\n",
      "[25/50] Loss: 0.251065, Acc: 0.930625\n",
      "[25/50] Loss: 0.241330, Acc: 0.931667\n",
      "[25/50] Loss: 0.252500, Acc: 0.930382\n",
      "[25/50] Loss: 0.253009, Acc: 0.931120\n",
      "[25/50] Loss: 0.256442, Acc: 0.929500\n",
      "[25/50] Loss: 0.254406, Acc: 0.929601\n",
      "Finish 25 epoch, Loss: 0.253973, Acc: 0.929650\n",
      "Test Loss: 0.270358, Acc: 0.923200\n",
      "\n",
      "epoch 26\n",
      "**********\n",
      "[26/50] Loss: 0.251555, Acc: 0.933021\n",
      "[26/50] Loss: 0.249166, Acc: 0.932187\n",
      "[26/50] Loss: 0.251872, Acc: 0.931285\n",
      "[26/50] Loss: 0.254638, Acc: 0.929870\n",
      "[26/50] Loss: 0.254304, Acc: 0.929792\n",
      "[26/50] Loss: 0.253160, Acc: 0.929792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish 26 epoch, Loss: 0.253029, Acc: 0.929950\n",
      "Test Loss: 0.271120, Acc: 0.924500\n",
      "\n",
      "epoch 27\n",
      "**********\n",
      "[27/50] Loss: 0.254045, Acc: 0.930833\n",
      "[27/50] Loss: 0.252717, Acc: 0.928281\n",
      "[27/50] Loss: 0.254951, Acc: 0.928299\n",
      "[27/50] Loss: 0.253755, Acc: 0.929427\n",
      "[27/50] Loss: 0.253360, Acc: 0.929271\n",
      "[27/50] Loss: 0.253739, Acc: 0.929913\n",
      "Finish 27 epoch, Loss: 0.253230, Acc: 0.930133\n",
      "Test Loss: 0.270851, Acc: 0.923400\n",
      "\n",
      "epoch 28\n",
      "**********\n",
      "[28/50] Loss: 0.249377, Acc: 0.931250\n",
      "[28/50] Loss: 0.248863, Acc: 0.932396\n",
      "[28/50] Loss: 0.251658, Acc: 0.932326\n",
      "[28/50] Loss: 0.252603, Acc: 0.931172\n",
      "[28/50] Loss: 0.252195, Acc: 0.930750\n",
      "[28/50] Loss: 0.252976, Acc: 0.930556\n",
      "Finish 28 epoch, Loss: 0.252475, Acc: 0.930400\n",
      "Test Loss: 0.268320, Acc: 0.926200\n",
      "\n",
      "epoch 29\n",
      "**********\n",
      "[29/50] Loss: 0.242651, Acc: 0.933333\n",
      "[29/50] Loss: 0.252287, Acc: 0.930000\n",
      "[29/50] Loss: 0.253601, Acc: 0.930035\n",
      "[29/50] Loss: 0.251171, Acc: 0.930625\n",
      "[29/50] Loss: 0.253319, Acc: 0.930438\n",
      "[29/50] Loss: 0.251585, Acc: 0.930816\n",
      "Finish 29 epoch, Loss: 0.251843, Acc: 0.930633\n",
      "Test Loss: 0.270927, Acc: 0.923000\n",
      "\n",
      "epoch 30\n",
      "**********\n",
      "[30/50] Loss: 0.231204, Acc: 0.933229\n",
      "[30/50] Loss: 0.243066, Acc: 0.930625\n",
      "[30/50] Loss: 0.245687, Acc: 0.931007\n",
      "[30/50] Loss: 0.249003, Acc: 0.930573\n",
      "[30/50] Loss: 0.248518, Acc: 0.930292\n",
      "[30/50] Loss: 0.250918, Acc: 0.930069\n",
      "Finish 30 epoch, Loss: 0.251838, Acc: 0.930217\n",
      "Test Loss: 0.272276, Acc: 0.922800\n",
      "\n",
      "epoch 31\n",
      "**********\n",
      "[31/50] Loss: 0.244368, Acc: 0.932083\n",
      "[31/50] Loss: 0.256407, Acc: 0.930208\n",
      "[31/50] Loss: 0.248770, Acc: 0.931076\n",
      "[31/50] Loss: 0.253819, Acc: 0.929870\n",
      "[31/50] Loss: 0.252398, Acc: 0.930458\n",
      "[31/50] Loss: 0.251261, Acc: 0.930729\n",
      "Finish 31 epoch, Loss: 0.251103, Acc: 0.930617\n",
      "Test Loss: 0.272433, Acc: 0.924800\n",
      "\n",
      "epoch 32\n",
      "**********\n",
      "[32/50] Loss: 0.249414, Acc: 0.934896\n",
      "[32/50] Loss: 0.249038, Acc: 0.932760\n",
      "[32/50] Loss: 0.254115, Acc: 0.931319\n",
      "[32/50] Loss: 0.253437, Acc: 0.930469\n",
      "[32/50] Loss: 0.253859, Acc: 0.930146\n",
      "[32/50] Loss: 0.251764, Acc: 0.930851\n",
      "Finish 32 epoch, Loss: 0.250916, Acc: 0.930900\n",
      "Test Loss: 0.273100, Acc: 0.924200\n",
      "\n",
      "epoch 33\n",
      "**********\n",
      "[33/50] Loss: 0.253835, Acc: 0.929688\n",
      "[33/50] Loss: 0.249615, Acc: 0.931146\n",
      "[33/50] Loss: 0.248717, Acc: 0.930903\n",
      "[33/50] Loss: 0.249640, Acc: 0.931589\n",
      "[33/50] Loss: 0.252382, Acc: 0.930750\n",
      "[33/50] Loss: 0.250031, Acc: 0.931354\n",
      "Finish 33 epoch, Loss: 0.249949, Acc: 0.931167\n",
      "Test Loss: 0.269676, Acc: 0.924600\n",
      "\n",
      "epoch 34\n",
      "**********\n",
      "[34/50] Loss: 0.258543, Acc: 0.926771\n",
      "[34/50] Loss: 0.246083, Acc: 0.929583\n",
      "[34/50] Loss: 0.250139, Acc: 0.928542\n",
      "[34/50] Loss: 0.246587, Acc: 0.930052\n",
      "[34/50] Loss: 0.249489, Acc: 0.930813\n",
      "[34/50] Loss: 0.250906, Acc: 0.930382\n",
      "Finish 34 epoch, Loss: 0.249665, Acc: 0.930600\n",
      "Test Loss: 0.269368, Acc: 0.925700\n",
      "\n",
      "epoch 35\n",
      "**********\n",
      "[35/50] Loss: 0.247981, Acc: 0.931562\n",
      "[35/50] Loss: 0.243979, Acc: 0.932656\n",
      "[35/50] Loss: 0.244109, Acc: 0.931701\n",
      "[35/50] Loss: 0.248541, Acc: 0.931510\n",
      "[35/50] Loss: 0.246615, Acc: 0.931458\n",
      "[35/50] Loss: 0.248258, Acc: 0.931059\n",
      "Finish 35 epoch, Loss: 0.248694, Acc: 0.931050\n",
      "Test Loss: 0.272927, Acc: 0.924800\n",
      "\n",
      "epoch 36\n",
      "**********\n",
      "[36/50] Loss: 0.241335, Acc: 0.934688\n",
      "[36/50] Loss: 0.245381, Acc: 0.933438\n",
      "[36/50] Loss: 0.245331, Acc: 0.932847\n",
      "[36/50] Loss: 0.249326, Acc: 0.931302\n",
      "[36/50] Loss: 0.250416, Acc: 0.931458\n",
      "[36/50] Loss: 0.249834, Acc: 0.931458\n",
      "Finish 36 epoch, Loss: 0.248761, Acc: 0.931500\n",
      "Test Loss: 0.275879, Acc: 0.924300\n",
      "\n",
      "epoch 37\n",
      "**********\n",
      "[37/50] Loss: 0.229201, Acc: 0.933750\n",
      "[37/50] Loss: 0.236186, Acc: 0.932865\n",
      "[37/50] Loss: 0.244115, Acc: 0.931493\n",
      "[37/50] Loss: 0.248180, Acc: 0.930625\n",
      "[37/50] Loss: 0.249224, Acc: 0.930937\n",
      "[37/50] Loss: 0.249532, Acc: 0.930399\n",
      "Finish 37 epoch, Loss: 0.248387, Acc: 0.930700\n",
      "Test Loss: 0.271748, Acc: 0.926700\n",
      "\n",
      "epoch 38\n",
      "**********\n",
      "[38/50] Loss: 0.245975, Acc: 0.929479\n",
      "[38/50] Loss: 0.241933, Acc: 0.931979\n",
      "[38/50] Loss: 0.242549, Acc: 0.933021\n",
      "[38/50] Loss: 0.248106, Acc: 0.931250\n",
      "[38/50] Loss: 0.245794, Acc: 0.931583\n",
      "[38/50] Loss: 0.245322, Acc: 0.931944\n",
      "Finish 38 epoch, Loss: 0.247670, Acc: 0.931467\n",
      "Test Loss: 0.272545, Acc: 0.924300\n",
      "\n",
      "epoch 39\n",
      "**********\n",
      "[39/50] Loss: 0.257484, Acc: 0.930937\n",
      "[39/50] Loss: 0.248327, Acc: 0.931510\n",
      "[39/50] Loss: 0.250585, Acc: 0.931493\n",
      "[39/50] Loss: 0.248319, Acc: 0.931901\n",
      "[39/50] Loss: 0.248147, Acc: 0.931167\n",
      "[39/50] Loss: 0.246841, Acc: 0.931615\n",
      "Finish 39 epoch, Loss: 0.247830, Acc: 0.931483\n",
      "Test Loss: 0.269197, Acc: 0.924700\n",
      "\n",
      "epoch 40\n",
      "**********\n",
      "[40/50] Loss: 0.250131, Acc: 0.930625\n",
      "[40/50] Loss: 0.255213, Acc: 0.929948\n",
      "[40/50] Loss: 0.253327, Acc: 0.930347\n",
      "[40/50] Loss: 0.249621, Acc: 0.931016\n",
      "[40/50] Loss: 0.249001, Acc: 0.930917\n",
      "[40/50] Loss: 0.248191, Acc: 0.930781\n",
      "Finish 40 epoch, Loss: 0.247526, Acc: 0.930917\n",
      "Test Loss: 0.268880, Acc: 0.925300\n",
      "\n",
      "epoch 41\n",
      "**********\n",
      "[41/50] Loss: 0.249521, Acc: 0.930833\n",
      "[41/50] Loss: 0.246462, Acc: 0.931354\n",
      "[41/50] Loss: 0.243900, Acc: 0.931771\n",
      "[41/50] Loss: 0.242411, Acc: 0.932734\n",
      "[41/50] Loss: 0.245077, Acc: 0.932083\n",
      "[41/50] Loss: 0.246915, Acc: 0.931354\n",
      "Finish 41 epoch, Loss: 0.246945, Acc: 0.931350\n",
      "Test Loss: 0.267790, Acc: 0.926400\n",
      "\n",
      "epoch 42\n",
      "**********\n",
      "[42/50] Loss: 0.232820, Acc: 0.938333\n",
      "[42/50] Loss: 0.236187, Acc: 0.935052\n",
      "[42/50] Loss: 0.244222, Acc: 0.933368\n",
      "[42/50] Loss: 0.246844, Acc: 0.931771\n",
      "[42/50] Loss: 0.245017, Acc: 0.931958\n",
      "[42/50] Loss: 0.246518, Acc: 0.931667\n",
      "Finish 42 epoch, Loss: 0.246697, Acc: 0.931550\n",
      "Test Loss: 0.270026, Acc: 0.924100\n",
      "\n",
      "epoch 43\n",
      "**********\n",
      "[43/50] Loss: 0.244713, Acc: 0.930208\n",
      "[43/50] Loss: 0.241416, Acc: 0.932344\n",
      "[43/50] Loss: 0.250750, Acc: 0.930660\n",
      "[43/50] Loss: 0.246784, Acc: 0.931719\n",
      "[43/50] Loss: 0.244304, Acc: 0.932438\n",
      "[43/50] Loss: 0.246787, Acc: 0.931510\n",
      "Finish 43 epoch, Loss: 0.246189, Acc: 0.932050\n",
      "Test Loss: 0.271697, Acc: 0.924700\n",
      "\n",
      "epoch 44\n",
      "**********\n",
      "[44/50] Loss: 0.244068, Acc: 0.932292\n",
      "[44/50] Loss: 0.243314, Acc: 0.933750\n",
      "[44/50] Loss: 0.246162, Acc: 0.931910\n",
      "[44/50] Loss: 0.245626, Acc: 0.932240\n",
      "[44/50] Loss: 0.243947, Acc: 0.932875\n",
      "[44/50] Loss: 0.246339, Acc: 0.932101\n",
      "Finish 44 epoch, Loss: 0.246088, Acc: 0.931783\n",
      "Test Loss: 0.275804, Acc: 0.927000\n",
      "\n",
      "epoch 45\n",
      "**********\n",
      "[45/50] Loss: 0.239162, Acc: 0.932917\n",
      "[45/50] Loss: 0.246612, Acc: 0.930521\n",
      "[45/50] Loss: 0.243973, Acc: 0.931910\n",
      "[45/50] Loss: 0.243887, Acc: 0.932005\n",
      "[45/50] Loss: 0.245123, Acc: 0.932125\n",
      "[45/50] Loss: 0.246578, Acc: 0.931285\n",
      "Finish 45 epoch, Loss: 0.245563, Acc: 0.931650\n",
      "Test Loss: 0.275350, Acc: 0.923700\n",
      "\n",
      "epoch 46\n",
      "**********\n",
      "[46/50] Loss: 0.250997, Acc: 0.927708\n",
      "[46/50] Loss: 0.247562, Acc: 0.930625\n",
      "[46/50] Loss: 0.246634, Acc: 0.931181\n",
      "[46/50] Loss: 0.242803, Acc: 0.932396\n",
      "[46/50] Loss: 0.243047, Acc: 0.932583\n",
      "[46/50] Loss: 0.245626, Acc: 0.931927\n",
      "Finish 46 epoch, Loss: 0.245187, Acc: 0.931900\n",
      "Test Loss: 0.267622, Acc: 0.925800\n",
      "\n",
      "epoch 47\n",
      "**********\n",
      "[47/50] Loss: 0.247767, Acc: 0.933646\n",
      "[47/50] Loss: 0.245555, Acc: 0.933073\n",
      "[47/50] Loss: 0.242212, Acc: 0.933576\n",
      "[47/50] Loss: 0.243824, Acc: 0.933255\n",
      "[47/50] Loss: 0.246483, Acc: 0.931854\n",
      "[47/50] Loss: 0.246496, Acc: 0.931493\n",
      "Finish 47 epoch, Loss: 0.244848, Acc: 0.931850\n",
      "Test Loss: 0.271110, Acc: 0.923800\n",
      "\n",
      "epoch 48\n",
      "**********\n",
      "[48/50] Loss: 0.246644, Acc: 0.934063\n",
      "[48/50] Loss: 0.246065, Acc: 0.931458\n",
      "[48/50] Loss: 0.244279, Acc: 0.932292\n",
      "[48/50] Loss: 0.248421, Acc: 0.931849\n",
      "[48/50] Loss: 0.246878, Acc: 0.931813\n",
      "[48/50] Loss: 0.244736, Acc: 0.932257\n",
      "Finish 48 epoch, Loss: 0.244492, Acc: 0.932150\n",
      "Test Loss: 0.276555, Acc: 0.921200\n",
      "\n",
      "epoch 49\n",
      "**********\n",
      "[49/50] Loss: 0.245202, Acc: 0.931562\n",
      "[49/50] Loss: 0.242421, Acc: 0.931458\n",
      "[49/50] Loss: 0.242885, Acc: 0.931910\n",
      "[49/50] Loss: 0.243176, Acc: 0.931276\n",
      "[49/50] Loss: 0.245864, Acc: 0.931083\n",
      "[49/50] Loss: 0.244003, Acc: 0.931441\n",
      "Finish 49 epoch, Loss: 0.244671, Acc: 0.931650\n",
      "Test Loss: 0.268475, Acc: 0.926500\n",
      "\n",
      "epoch 50\n",
      "**********\n",
      "[50/50] Loss: 0.233475, Acc: 0.934688\n",
      "[50/50] Loss: 0.236006, Acc: 0.935104\n",
      "[50/50] Loss: 0.239264, Acc: 0.934549\n",
      "[50/50] Loss: 0.241152, Acc: 0.933828\n",
      "[50/50] Loss: 0.242701, Acc: 0.933583\n",
      "[50/50] Loss: 0.244077, Acc: 0.932830\n",
      "Finish 50 epoch, Loss: 0.244432, Acc: 0.932550\n",
      "Test Loss: 0.270560, Acc: 0.926300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoches):\n",
    "\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "\n",
    "    print('*' * 10)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    running_acc = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "\n",
    "        img, label = data\n",
    "\n",
    "        img = img.view(img.size(0), -1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "\n",
    "            img = Variable(img).cuda()\n",
    "\n",
    "            label = Variable(label).cuda()\n",
    "\n",
    "        else:\n",
    "\n",
    "            img = Variable(img)\n",
    "\n",
    "            label = Variable(label)\n",
    "\n",
    "        # 向前传播\n",
    "\n",
    "        out = model(img)\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        num_correct = (pred == label).sum()\n",
    "\n",
    "        running_acc += num_correct.item()\n",
    "\n",
    "        # 向后传播\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        if i % 300 == 0:\n",
    "\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "\n",
    "                running_acc / (batch_size * i)))\n",
    "\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n",
    "\n",
    "            train_dataset))))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0.\n",
    "\n",
    "    eval_acc = 0.\n",
    "\n",
    "    for data in test_loader:\n",
    "\n",
    "        img, label = data\n",
    "\n",
    "        img = img.view(img.size(0), -1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "\n",
    "            img = Variable(img, volatile=True).cuda()\n",
    "\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "\n",
    "        else:\n",
    "\n",
    "            img = Variable(img, volatile=True)\n",
    "\n",
    "            label = Variable(label, volatile=True)\n",
    "\n",
    "        out = model(img)\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        eval_loss += loss.item() * label.size(0)\n",
    "\n",
    "        _, pred = torch.max(out, 1)\n",
    "\n",
    "        num_correct = (pred == label).sum()\n",
    "\n",
    "        eval_acc += num_correct.item()\n",
    "\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "\n",
    "        test_dataset)), eval_acc / (len(test_dataset))))\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "torch.save(model.state_dict(), './neural_network.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

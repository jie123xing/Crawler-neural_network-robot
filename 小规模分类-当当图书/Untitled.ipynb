{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import pymysql\n",
    "import random\n",
    "import json  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 读取数据\n",
    "with open('2shelf.json', 'r',encoding='utf-8-sig') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassification():################获取全部图书分类信息\n",
    "        resp=urlopen('http://category.dangdang.com/?ref=www-0-C')\n",
    "        soup=BeautifulSoup(resp,'html.parser')\n",
    "        ##############目录\n",
    "        General_classification =soup.find('div',id='floor_1')\n",
    "    \n",
    "        Gclass,Sclass,sclassion=[],[],[]###总目录和分目录获取\n",
    "        for i in General_classification:\n",
    "            try:\n",
    "                Gclass.append(i.a.string.encode('iso-8859-1').decode('gb2312'))####需要编码解码消除乱码\n",
    "                Sclass.append(i.ul)\n",
    "            except:\n",
    "                Gclass.append('港台图书')###特殊处理\n",
    "                Sclass.append(i.ul)  \n",
    "                \n",
    "        del Gclass[0];del Gclass[-1];del Sclass[0];del Gclass[-1] #####删除头尾无用部分  53-->51个数\n",
    "        \n",
    "        sclassion,sclassurl,lensclass=[],[],[] #####分目录名，url,每个分类的长度，调用时sclassion[x:x+1]\n",
    "        for i in range(len(Gclass)):\n",
    "            lensc=0    ###计数每个分类的个数\n",
    "            for j in Sclass[i]:\n",
    "                if j.a.string.encode('iso-8859-1').decode('gb2312')=='更多':\n",
    "                     continue\n",
    "                sclassion.append(j.a.string.encode('iso-8859-1').decode('gb2312'))\n",
    "                sclassurl.append(j.a.get('href'))\n",
    "                lensc+=1\n",
    "            lensclass.append(lensc)        \n",
    "            \n",
    "        return Gclass,sclassion,sclassurl,lensclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbookinfo(Gclass,sclassion,sclassurl,lensclass):################获取图书信息\n",
    "        pivot=0###########标定位置，方便小分类分段截取\n",
    "        books=1\n",
    "        shelfpivot=['休闲/爱好','孕产/胎教','家庭/家居','科普读物','法文原版书','网络课程']\n",
    "        for i in range(len(Gclass)):\n",
    "            if Gclass[i] not in shelfpivot:#####去掉空,和数量较多的分类\n",
    "                continue\n",
    "            gclass=Gclass[i]            ####大分类49\n",
    "            sclass=sclassion[pivot:pivot+lensclass[i]]######小分类679\n",
    "            bookurl=sclassurl[pivot:pivot+lensclass[i]]   #######小分类url-679\n",
    "            pivot+=lensclass[i] \n",
    "            \n",
    "            if Gclass[i] in shelfpivot:\n",
    "                bookshelf='%dshelf'%books\n",
    "                books+=1\n",
    "            #############  1----15-----15\n",
    "            for _ in range(lensclass[i]):\n",
    "                url=bookurl[_]\n",
    "                html = requests.get(url)\n",
    "                html.encoding = 'gb2312'\n",
    "                soup = BeautifulSoup(html.text, 'html.parser')########对url进行处理 ，进入分类书籍页面\n",
    "                book_title=soup.find_all('a',dd_name='单品图片')  #####为获取url集准备\n",
    "                for i in book_title:\n",
    "                    try:\n",
    "                        resp=urlopen(i.get('href'))\n",
    "                        soup=BeautifulSoup(resp,'html.parser')\n",
    "                        booktitle=soup.find('h1').get('title')    #####进入具体某本书的页面\n",
    "                        booktitle=booktitle[0:10]\n",
    "                        bookdetail=soup.find('span',class_='head_title_name').get('title')\n",
    "                        bookdetail=bookdetail[0:19]\n",
    "                        bookprice=float(soup.find('p',id='dd-price').text[2:].strip())\n",
    "                        author=soup.find('a',dd_name='作者').string\n",
    "                        press=soup.find('a',dd_name='出版社').string\n",
    "                        #publicationtime=soup.find_all('span',class_='t1')[2].text\n",
    "                        #publicationtime=publicationtime[5:-1]\n",
    "                        publicationtime=random.randint(-2000,2000)\n",
    "                        bookdetailurl=i.get('href')\n",
    "                        picurl=soup.find('img',id='largePic').get('src') \n",
    "                        path = 'images/'+bookshelf+'/' # 设置路径，也可设为相对路径\n",
    "                        response = requests.get(picurl,timeout=5)\n",
    "                        # 获取的文本实际上是图片的二进制文本\n",
    "                        img = response.content\n",
    "                        if img==None:\n",
    "                            continue\n",
    "                        bookinfo=[bookshelf,booktitle,publicationtime, author, press,bookprice,bookdetail,bookdetailurl]\n",
    "    \n",
    "                        writejson(bookinfo,gclass,sclass[_],path,img)\n",
    "                    except:\n",
    "                        pass\n",
    "                #print('1次小循环')\n",
    "            #print('大循环')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writejson(bookinfo,Gclass,sclassion,path,img):\n",
    "\n",
    "        Gclass,sclassion=Gclass.replace('/','-'),sclassion.replace('/','-')#####消除文件名中'/'\n",
    "        #bookinfo.append(Gclass)\n",
    "        #bookinfo.append(sclassion)\n",
    "        #print(bookinfo)\n",
    "        localpicurl=path+bookinfo[1]+'.jpg'\n",
    "        bookdict={'bookshelf':bookinfo[0],'booktitle':bookinfo[1],\n",
    "                  'publicationtime':bookinfo[2],'author':bookinfo[3],'press':bookinfo[4],\n",
    "                  'bookprice':bookinfo[5],'bookdetail':bookinfo[6],\n",
    "                  'Gclass':Gclass,'sclass':sclassion,'bookdetailurl':bookinfo[7],'localpicurl':localpicurl}\n",
    "        #print(bookdict)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # 判断目录是否存在\n",
    "            if not os.path.exists(path):\n",
    "                # 目录不存在创建，makedirs可以创建多级目录\n",
    "                os.makedirs(path)\n",
    "            with open(path+bookinfo[1]+'.jpg','wb') as fpic:\n",
    "                # 写入 JSON 数据\n",
    "                with open(bookinfo[0]+'.json', 'a',encoding='utf-8') as f:\n",
    "                            fpic.write(img)\n",
    "                            json.dump(bookdict, f,ensure_ascii=False,indent=4)\n",
    "                            f.write(',')\n",
    "                            #print('pic get')\n",
    "        except Exception as e:\n",
    "            print('保存失败', e,'booktitle:',bookinfo[1],'Gclass:',bookinfo[7],'sclass:',bookinfo[8])\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    Gclass,sclassion,sclassurl,lensclass=getClassification()#####50 679 679 50  ######length\n",
    "    getbookinfo(Gclass,sclassion,sclassurl,lensclass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
